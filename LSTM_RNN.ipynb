{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTdHO80orPNl",
        "outputId": "47f8429b-b999-4f5a-8e41-8075d52129c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z41epYunsGGd",
        "outputId": "78415432-1c18-44b3-df94-33918bc821f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-7025710ea99b>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  data = pd.read_csv('/content/IMDB.csv', sep = ',', engine='python',encoding='utf-8', error_bad_lines=True)\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/IMDB.csv', sep = ',', engine='python',encoding='utf-8', error_bad_lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MgqIyrVvsQVe",
        "outputId": "f6c38167-f9a3-4f0d-8301-1c0b1af84f1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8995060b-19f3-4102-8b18-2e1781d6bef2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8995060b-19f3-4102-8b18-2e1781d6bef2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8995060b-19f3-4102-8b18-2e1781d6bef2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8995060b-19f3-4102-8b18-2e1781d6bef2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6357344-f973-4ce7-be1c-bec1fd138deb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6357344-f973-4ce7-be1c-bec1fd138deb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6357344-f973-4ce7-be1c-bec1fd138deb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "0      One of the other reviewers has mentioned that ...  positive\n",
              "1      A wonderful little production. <br /><br />The...  positive\n",
              "2      I thought this was a wonderful way to spend ti...  positive\n",
              "3      Basically there's a family where a little boy ...  negative\n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
              "...                                                  ...       ...\n",
              "49995  I thought this movie did a down right good job...  positive\n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
              "49997  I am a Catholic taught in parochial elementary...  negative\n",
              "49998  I'm going to have to disagree with the previou...  negative\n",
              "49999  No one expects the Star Trek movies to be high...  negative\n",
              "\n",
              "[50000 rows x 2 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg_PMGHcsSvN",
        "outputId": "72934b87-af89-42d1-b010-f6488180f5db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python==3.10.12\n",
            "numpy==1.23.5\n",
            "torch==2.1.0+cu118\n",
            "torchtext==0.16.0+cpu\n",
            "matplotlib==3.7.1\n"
          ]
        }
      ],
      "source": [
        "from platform import python_version\n",
        "import numpy, matplotlib, pandas, torch, torchtext\n",
        "\n",
        "print(\"python==\" + python_version())\n",
        "print(\"numpy==\" + numpy.__version__)\n",
        "print(\"torch==\" + torch.__version__)\n",
        "print(\"torchtext==\" + torchtext.__version__)\n",
        "print(\"matplotlib==\" + matplotlib.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MOLA5RDNsrSI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into training and temporary (validation + test) sets\n",
        "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the temporary data into validation and test sets\n",
        "validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHIRrHzuzPeZ",
        "outputId": "79f8f453-0730-4d70-f5f3-4f8d5027dac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['review', 'sentiment'], dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi3FiFcSzUSk",
        "outputId": "029b3742-c427-4ca5-d237-a5ee2c2b00c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review       That's what I kept asking myself during the ma...\n",
              "sentiment                                             negative\n",
              "Name: 39087, dtype: object"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKnfxDBmtLr9",
        "outputId": "5275f119-8f26-4e29-9ef5-855de5e3122c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((40000, 2), (5000, 2), (5000, 2))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape, validation_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rP46FLlNJCjL"
      },
      "outputs": [],
      "source": [
        "!pip install portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM0m81FJuMVh",
        "outputId": "60a0bce1-5b25-4f09-e189-9ba823afaf36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(train_data.review[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "9UqkwPbmWJsL",
        "outputId": "a60ba907-3923-4fb0-c572-567d9c86abdc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_text=train_data.review[0]\n",
        "example_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "KrwS19MruOjO",
        "outputId": "86250951-4086-40f0-fd1e-3594a2c3ffa6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = re.sub(\"<[^>]*>\", \"\", example_text)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ShaKUyAMubi4",
        "outputId": "e5c99e55-1953-4a86-a5ca-60960b70fc10"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = text.lower()\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QgBEkWxufjP",
        "outputId": "e2794b74-ed3a-4048-d2fa-1e1db47e6fb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
        "emoticons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ZWBk7imkuk1Q",
        "outputId": "32476329-acdc-45a0-8c1c-d4d239493f30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'one of the other reviewers has mentioned that after watching just 1 oz episode you ll be hooked they are right as this is exactly what happened with me the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the word it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to many aryans muslims gangstas latinos christians italians irish and more so scuffles death stares dodgy dealings and shady agreements are never far away i would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare forget pretty pictures painted for mainstream audiences forget charm forget romance oz doesn t mess around the first episode i ever saw struck me as so nasty it was surreal i couldn t say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards who ll be sold out for a nickel inmates who ll kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewing thats if you can get in touch with your darker side '"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = re.sub(\"[\\W]+\", \" \", text)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gf_djn2UtWIW"
      },
      "outputs": [],
      "source": [
        "def tokenizer(text):\n",
        "    # step 1. remove HTML tags. they are not helpful in understanding the sentiments of a review\n",
        "    # step 2: use lowercase for all text to keep symmetry\n",
        "    # step 3: extract emoticons. keep them as they are important sentiment signals\n",
        "    # step 4: remove punctuation marks\n",
        "    # step 5: put back emoticons\n",
        "    # step 6: generate word tokens\n",
        "    text = re.sub(\"<[^>]*>\", \"\", text)\n",
        "    text = text.lower()\n",
        "    emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text)\n",
        "    text = re.sub(\"[\\W]+\", \" \", text)\n",
        "    text = text + \" \".join(emoticons).replace(\"-\", \"\")\n",
        "    tokenized = text.split()\n",
        "    return tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZwJClNctmgR",
        "outputId": "a0bd466d-fe39-4b6f-de52-28e00558bee8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'other',\n",
              " 'reviewers',\n",
              " 'has',\n",
              " 'mentioned',\n",
              " 'that',\n",
              " 'after',\n",
              " 'watching',\n",
              " 'just',\n",
              " '1',\n",
              " 'oz',\n",
              " 'episode',\n",
              " 'you',\n",
              " 'll',\n",
              " 'be',\n",
              " 'hooked',\n",
              " 'they',\n",
              " 'are',\n",
              " 'right',\n",
              " 'as',\n",
              " 'this',\n",
              " 'is',\n",
              " 'exactly',\n",
              " 'what',\n",
              " 'happened',\n",
              " 'with',\n",
              " 'me',\n",
              " 'the',\n",
              " 'first',\n",
              " 'thing',\n",
              " 'that',\n",
              " 'struck',\n",
              " 'me',\n",
              " 'about',\n",
              " 'oz',\n",
              " 'was',\n",
              " 'its',\n",
              " 'brutality',\n",
              " 'and',\n",
              " 'unflinching',\n",
              " 'scenes',\n",
              " 'of',\n",
              " 'violence',\n",
              " 'which',\n",
              " 'set',\n",
              " 'in',\n",
              " 'right',\n",
              " 'from',\n",
              " 'the',\n",
              " 'word',\n",
              " 'go',\n",
              " 'trust',\n",
              " 'me',\n",
              " 'this',\n",
              " 'is',\n",
              " 'not',\n",
              " 'a',\n",
              " 'show',\n",
              " 'for',\n",
              " 'the',\n",
              " 'faint',\n",
              " 'hearted',\n",
              " 'or',\n",
              " 'timid',\n",
              " 'this',\n",
              " 'show',\n",
              " 'pulls',\n",
              " 'no',\n",
              " 'punches',\n",
              " 'with',\n",
              " 'regards',\n",
              " 'to',\n",
              " 'drugs',\n",
              " 'sex',\n",
              " 'or',\n",
              " 'violence',\n",
              " 'its',\n",
              " 'is',\n",
              " 'hardcore',\n",
              " 'in',\n",
              " 'the',\n",
              " 'classic',\n",
              " 'use',\n",
              " 'of',\n",
              " 'the',\n",
              " 'word',\n",
              " 'it',\n",
              " 'is',\n",
              " 'called',\n",
              " 'oz',\n",
              " 'as',\n",
              " 'that',\n",
              " 'is',\n",
              " 'the',\n",
              " 'nickname',\n",
              " 'given',\n",
              " 'to',\n",
              " 'the',\n",
              " 'oswald',\n",
              " 'maximum',\n",
              " 'security',\n",
              " 'state',\n",
              " 'penitentary',\n",
              " 'it',\n",
              " 'focuses',\n",
              " 'mainly',\n",
              " 'on',\n",
              " 'emerald',\n",
              " 'city',\n",
              " 'an',\n",
              " 'experimental',\n",
              " 'section',\n",
              " 'of',\n",
              " 'the',\n",
              " 'prison',\n",
              " 'where',\n",
              " 'all',\n",
              " 'the',\n",
              " 'cells',\n",
              " 'have',\n",
              " 'glass',\n",
              " 'fronts',\n",
              " 'and',\n",
              " 'face',\n",
              " 'inwards',\n",
              " 'so',\n",
              " 'privacy',\n",
              " 'is',\n",
              " 'not',\n",
              " 'high',\n",
              " 'on',\n",
              " 'the',\n",
              " 'agenda',\n",
              " 'em',\n",
              " 'city',\n",
              " 'is',\n",
              " 'home',\n",
              " 'to',\n",
              " 'many',\n",
              " 'aryans',\n",
              " 'muslims',\n",
              " 'gangstas',\n",
              " 'latinos',\n",
              " 'christians',\n",
              " 'italians',\n",
              " 'irish',\n",
              " 'and',\n",
              " 'more',\n",
              " 'so',\n",
              " 'scuffles',\n",
              " 'death',\n",
              " 'stares',\n",
              " 'dodgy',\n",
              " 'dealings',\n",
              " 'and',\n",
              " 'shady',\n",
              " 'agreements',\n",
              " 'are',\n",
              " 'never',\n",
              " 'far',\n",
              " 'away',\n",
              " 'i',\n",
              " 'would',\n",
              " 'say',\n",
              " 'the',\n",
              " 'main',\n",
              " 'appeal',\n",
              " 'of',\n",
              " 'the',\n",
              " 'show',\n",
              " 'is',\n",
              " 'due',\n",
              " 'to',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'that',\n",
              " 'it',\n",
              " 'goes',\n",
              " 'where',\n",
              " 'other',\n",
              " 'shows',\n",
              " 'wouldn',\n",
              " 't',\n",
              " 'dare',\n",
              " 'forget',\n",
              " 'pretty',\n",
              " 'pictures',\n",
              " 'painted',\n",
              " 'for',\n",
              " 'mainstream',\n",
              " 'audiences',\n",
              " 'forget',\n",
              " 'charm',\n",
              " 'forget',\n",
              " 'romance',\n",
              " 'oz',\n",
              " 'doesn',\n",
              " 't',\n",
              " 'mess',\n",
              " 'around',\n",
              " 'the',\n",
              " 'first',\n",
              " 'episode',\n",
              " 'i',\n",
              " 'ever',\n",
              " 'saw',\n",
              " 'struck',\n",
              " 'me',\n",
              " 'as',\n",
              " 'so',\n",
              " 'nasty',\n",
              " 'it',\n",
              " 'was',\n",
              " 'surreal',\n",
              " 'i',\n",
              " 'couldn',\n",
              " 't',\n",
              " 'say',\n",
              " 'i',\n",
              " 'was',\n",
              " 'ready',\n",
              " 'for',\n",
              " 'it',\n",
              " 'but',\n",
              " 'as',\n",
              " 'i',\n",
              " 'watched',\n",
              " 'more',\n",
              " 'i',\n",
              " 'developed',\n",
              " 'a',\n",
              " 'taste',\n",
              " 'for',\n",
              " 'oz',\n",
              " 'and',\n",
              " 'got',\n",
              " 'accustomed',\n",
              " 'to',\n",
              " 'the',\n",
              " 'high',\n",
              " 'levels',\n",
              " 'of',\n",
              " 'graphic',\n",
              " 'violence',\n",
              " 'not',\n",
              " 'just',\n",
              " 'violence',\n",
              " 'but',\n",
              " 'injustice',\n",
              " 'crooked',\n",
              " 'guards',\n",
              " 'who',\n",
              " 'll',\n",
              " 'be',\n",
              " 'sold',\n",
              " 'out',\n",
              " 'for',\n",
              " 'a',\n",
              " 'nickel',\n",
              " 'inmates',\n",
              " 'who',\n",
              " 'll',\n",
              " 'kill',\n",
              " 'on',\n",
              " 'order',\n",
              " 'and',\n",
              " 'get',\n",
              " 'away',\n",
              " 'with',\n",
              " 'it',\n",
              " 'well',\n",
              " 'mannered',\n",
              " 'middle',\n",
              " 'class',\n",
              " 'inmates',\n",
              " 'being',\n",
              " 'turned',\n",
              " 'into',\n",
              " 'prison',\n",
              " 'bitches',\n",
              " 'due',\n",
              " 'to',\n",
              " 'their',\n",
              " 'lack',\n",
              " 'of',\n",
              " 'street',\n",
              " 'skills',\n",
              " 'or',\n",
              " 'prison',\n",
              " 'experience',\n",
              " 'watching',\n",
              " 'oz',\n",
              " 'you',\n",
              " 'may',\n",
              " 'become',\n",
              " 'comfortable',\n",
              " 'with',\n",
              " 'what',\n",
              " 'is',\n",
              " 'uncomfortable',\n",
              " 'viewing',\n",
              " 'thats',\n",
              " 'if',\n",
              " 'you',\n",
              " 'can',\n",
              " 'get',\n",
              " 'in',\n",
              " 'touch',\n",
              " 'with',\n",
              " 'your',\n",
              " 'darker',\n",
              " 'side']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_tokens = tokenizer(example_text)\n",
        "example_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-5jt0Ckuo6o",
        "outputId": "fdfdf638-a763-41f1-f4b1-64153383014a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'one': 1,\n",
              "         'of': 7,\n",
              "         'the': 16,\n",
              "         'other': 2,\n",
              "         'reviewers': 1,\n",
              "         'has': 1,\n",
              "         'mentioned': 1,\n",
              "         'that': 4,\n",
              "         'after': 1,\n",
              "         'watching': 2,\n",
              "         'just': 2,\n",
              "         '1': 1,\n",
              "         'oz': 6,\n",
              "         'episode': 2,\n",
              "         'you': 3,\n",
              "         'll': 3,\n",
              "         'be': 2,\n",
              "         'hooked': 1,\n",
              "         'they': 1,\n",
              "         'are': 2,\n",
              "         'right': 2,\n",
              "         'as': 4,\n",
              "         'this': 3,\n",
              "         'is': 9,\n",
              "         'exactly': 1,\n",
              "         'what': 2,\n",
              "         'happened': 1,\n",
              "         'with': 5,\n",
              "         'me': 4,\n",
              "         'first': 2,\n",
              "         'thing': 1,\n",
              "         'struck': 2,\n",
              "         'about': 1,\n",
              "         'was': 3,\n",
              "         'its': 2,\n",
              "         'brutality': 1,\n",
              "         'and': 6,\n",
              "         'unflinching': 1,\n",
              "         'scenes': 1,\n",
              "         'violence': 4,\n",
              "         'which': 1,\n",
              "         'set': 1,\n",
              "         'in': 3,\n",
              "         'from': 1,\n",
              "         'word': 2,\n",
              "         'go': 1,\n",
              "         'trust': 1,\n",
              "         'not': 3,\n",
              "         'a': 3,\n",
              "         'show': 3,\n",
              "         'for': 5,\n",
              "         'faint': 1,\n",
              "         'hearted': 1,\n",
              "         'or': 3,\n",
              "         'timid': 1,\n",
              "         'pulls': 1,\n",
              "         'no': 1,\n",
              "         'punches': 1,\n",
              "         'regards': 1,\n",
              "         'to': 6,\n",
              "         'drugs': 1,\n",
              "         'sex': 1,\n",
              "         'hardcore': 1,\n",
              "         'classic': 1,\n",
              "         'use': 1,\n",
              "         'it': 6,\n",
              "         'called': 1,\n",
              "         'nickname': 1,\n",
              "         'given': 1,\n",
              "         'oswald': 1,\n",
              "         'maximum': 1,\n",
              "         'security': 1,\n",
              "         'state': 1,\n",
              "         'penitentary': 1,\n",
              "         'focuses': 1,\n",
              "         'mainly': 1,\n",
              "         'on': 3,\n",
              "         'emerald': 1,\n",
              "         'city': 2,\n",
              "         'an': 1,\n",
              "         'experimental': 1,\n",
              "         'section': 1,\n",
              "         'prison': 3,\n",
              "         'where': 2,\n",
              "         'all': 1,\n",
              "         'cells': 1,\n",
              "         'have': 1,\n",
              "         'glass': 1,\n",
              "         'fronts': 1,\n",
              "         'face': 1,\n",
              "         'inwards': 1,\n",
              "         'so': 3,\n",
              "         'privacy': 1,\n",
              "         'high': 2,\n",
              "         'agenda': 1,\n",
              "         'em': 1,\n",
              "         'home': 1,\n",
              "         'many': 1,\n",
              "         'aryans': 1,\n",
              "         'muslims': 1,\n",
              "         'gangstas': 1,\n",
              "         'latinos': 1,\n",
              "         'christians': 1,\n",
              "         'italians': 1,\n",
              "         'irish': 1,\n",
              "         'more': 2,\n",
              "         'scuffles': 1,\n",
              "         'death': 1,\n",
              "         'stares': 1,\n",
              "         'dodgy': 1,\n",
              "         'dealings': 1,\n",
              "         'shady': 1,\n",
              "         'agreements': 1,\n",
              "         'never': 1,\n",
              "         'far': 1,\n",
              "         'away': 2,\n",
              "         'i': 6,\n",
              "         'would': 1,\n",
              "         'say': 2,\n",
              "         'main': 1,\n",
              "         'appeal': 1,\n",
              "         'due': 2,\n",
              "         'fact': 1,\n",
              "         'goes': 1,\n",
              "         'shows': 1,\n",
              "         'wouldn': 1,\n",
              "         't': 3,\n",
              "         'dare': 1,\n",
              "         'forget': 3,\n",
              "         'pretty': 1,\n",
              "         'pictures': 1,\n",
              "         'painted': 1,\n",
              "         'mainstream': 1,\n",
              "         'audiences': 1,\n",
              "         'charm': 1,\n",
              "         'romance': 1,\n",
              "         'doesn': 1,\n",
              "         'mess': 1,\n",
              "         'around': 1,\n",
              "         'ever': 1,\n",
              "         'saw': 1,\n",
              "         'nasty': 1,\n",
              "         'surreal': 1,\n",
              "         'couldn': 1,\n",
              "         'ready': 1,\n",
              "         'but': 2,\n",
              "         'watched': 1,\n",
              "         'developed': 1,\n",
              "         'taste': 1,\n",
              "         'got': 1,\n",
              "         'accustomed': 1,\n",
              "         'levels': 1,\n",
              "         'graphic': 1,\n",
              "         'injustice': 1,\n",
              "         'crooked': 1,\n",
              "         'guards': 1,\n",
              "         'who': 2,\n",
              "         'sold': 1,\n",
              "         'out': 1,\n",
              "         'nickel': 1,\n",
              "         'inmates': 2,\n",
              "         'kill': 1,\n",
              "         'order': 1,\n",
              "         'get': 2,\n",
              "         'well': 1,\n",
              "         'mannered': 1,\n",
              "         'middle': 1,\n",
              "         'class': 1,\n",
              "         'being': 1,\n",
              "         'turned': 1,\n",
              "         'into': 1,\n",
              "         'bitches': 1,\n",
              "         'their': 1,\n",
              "         'lack': 1,\n",
              "         'street': 1,\n",
              "         'skills': 1,\n",
              "         'experience': 1,\n",
              "         'may': 1,\n",
              "         'become': 1,\n",
              "         'comfortable': 1,\n",
              "         'uncomfortable': 1,\n",
              "         'viewing': 1,\n",
              "         'thats': 1,\n",
              "         'if': 1,\n",
              "         'can': 1,\n",
              "         'touch': 1,\n",
              "         'your': 1,\n",
              "         'darker': 1,\n",
              "         'side': 1})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "token_counts = Counter()\n",
        "token_counts.update(example_tokens)\n",
        "token_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tshCRgfruv0S",
        "outputId": "119d572d-794e-4040-d3bb-0fd33b69221f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('the', 16),\n",
              " ('is', 9),\n",
              " ('of', 7),\n",
              " ('oz', 6),\n",
              " ('and', 6),\n",
              " ('to', 6),\n",
              " ('it', 6),\n",
              " ('i', 6),\n",
              " ('with', 5),\n",
              " ('for', 5),\n",
              " ('that', 4),\n",
              " ('as', 4),\n",
              " ('me', 4),\n",
              " ('violence', 4),\n",
              " ('you', 3),\n",
              " ('ll', 3),\n",
              " ('this', 3),\n",
              " ('was', 3),\n",
              " ('in', 3),\n",
              " ('not', 3),\n",
              " ('a', 3),\n",
              " ('show', 3),\n",
              " ('or', 3),\n",
              " ('on', 3),\n",
              " ('prison', 3),\n",
              " ('so', 3),\n",
              " ('t', 3),\n",
              " ('forget', 3),\n",
              " ('other', 2),\n",
              " ('watching', 2),\n",
              " ('just', 2),\n",
              " ('episode', 2),\n",
              " ('be', 2),\n",
              " ('are', 2),\n",
              " ('right', 2),\n",
              " ('what', 2),\n",
              " ('first', 2),\n",
              " ('struck', 2),\n",
              " ('its', 2),\n",
              " ('word', 2),\n",
              " ('city', 2),\n",
              " ('where', 2),\n",
              " ('high', 2),\n",
              " ('more', 2),\n",
              " ('away', 2),\n",
              " ('say', 2),\n",
              " ('due', 2),\n",
              " ('but', 2),\n",
              " ('who', 2),\n",
              " ('inmates', 2),\n",
              " ('get', 2),\n",
              " ('one', 1),\n",
              " ('reviewers', 1),\n",
              " ('has', 1),\n",
              " ('mentioned', 1),\n",
              " ('after', 1),\n",
              " ('1', 1),\n",
              " ('hooked', 1),\n",
              " ('they', 1),\n",
              " ('exactly', 1),\n",
              " ('happened', 1),\n",
              " ('thing', 1),\n",
              " ('about', 1),\n",
              " ('brutality', 1),\n",
              " ('unflinching', 1),\n",
              " ('scenes', 1),\n",
              " ('which', 1),\n",
              " ('set', 1),\n",
              " ('from', 1),\n",
              " ('go', 1),\n",
              " ('trust', 1),\n",
              " ('faint', 1),\n",
              " ('hearted', 1),\n",
              " ('timid', 1),\n",
              " ('pulls', 1),\n",
              " ('no', 1),\n",
              " ('punches', 1),\n",
              " ('regards', 1),\n",
              " ('drugs', 1),\n",
              " ('sex', 1),\n",
              " ('hardcore', 1),\n",
              " ('classic', 1),\n",
              " ('use', 1),\n",
              " ('called', 1),\n",
              " ('nickname', 1),\n",
              " ('given', 1),\n",
              " ('oswald', 1),\n",
              " ('maximum', 1),\n",
              " ('security', 1),\n",
              " ('state', 1),\n",
              " ('penitentary', 1),\n",
              " ('focuses', 1),\n",
              " ('mainly', 1),\n",
              " ('emerald', 1),\n",
              " ('an', 1),\n",
              " ('experimental', 1),\n",
              " ('section', 1),\n",
              " ('all', 1),\n",
              " ('cells', 1),\n",
              " ('have', 1),\n",
              " ('glass', 1),\n",
              " ('fronts', 1),\n",
              " ('face', 1),\n",
              " ('inwards', 1),\n",
              " ('privacy', 1),\n",
              " ('agenda', 1),\n",
              " ('em', 1),\n",
              " ('home', 1),\n",
              " ('many', 1),\n",
              " ('aryans', 1),\n",
              " ('muslims', 1),\n",
              " ('gangstas', 1),\n",
              " ('latinos', 1),\n",
              " ('christians', 1),\n",
              " ('italians', 1),\n",
              " ('irish', 1),\n",
              " ('scuffles', 1),\n",
              " ('death', 1),\n",
              " ('stares', 1),\n",
              " ('dodgy', 1),\n",
              " ('dealings', 1),\n",
              " ('shady', 1),\n",
              " ('agreements', 1),\n",
              " ('never', 1),\n",
              " ('far', 1),\n",
              " ('would', 1),\n",
              " ('main', 1),\n",
              " ('appeal', 1),\n",
              " ('fact', 1),\n",
              " ('goes', 1),\n",
              " ('shows', 1),\n",
              " ('wouldn', 1),\n",
              " ('dare', 1),\n",
              " ('pretty', 1),\n",
              " ('pictures', 1),\n",
              " ('painted', 1),\n",
              " ('mainstream', 1),\n",
              " ('audiences', 1),\n",
              " ('charm', 1),\n",
              " ('romance', 1),\n",
              " ('doesn', 1),\n",
              " ('mess', 1),\n",
              " ('around', 1),\n",
              " ('ever', 1),\n",
              " ('saw', 1),\n",
              " ('nasty', 1),\n",
              " ('surreal', 1),\n",
              " ('couldn', 1),\n",
              " ('ready', 1),\n",
              " ('watched', 1),\n",
              " ('developed', 1),\n",
              " ('taste', 1),\n",
              " ('got', 1),\n",
              " ('accustomed', 1),\n",
              " ('levels', 1),\n",
              " ('graphic', 1),\n",
              " ('injustice', 1),\n",
              " ('crooked', 1),\n",
              " ('guards', 1),\n",
              " ('sold', 1),\n",
              " ('out', 1),\n",
              " ('nickel', 1),\n",
              " ('kill', 1),\n",
              " ('order', 1),\n",
              " ('well', 1),\n",
              " ('mannered', 1),\n",
              " ('middle', 1),\n",
              " ('class', 1),\n",
              " ('being', 1),\n",
              " ('turned', 1),\n",
              " ('into', 1),\n",
              " ('bitches', 1),\n",
              " ('their', 1),\n",
              " ('lack', 1),\n",
              " ('street', 1),\n",
              " ('skills', 1),\n",
              " ('experience', 1),\n",
              " ('may', 1),\n",
              " ('become', 1),\n",
              " ('comfortable', 1),\n",
              " ('uncomfortable', 1),\n",
              " ('viewing', 1),\n",
              " ('thats', 1),\n",
              " ('if', 1),\n",
              " ('can', 1),\n",
              " ('touch', 1),\n",
              " ('your', 1),\n",
              " ('darker', 1),\n",
              " ('side', 1)]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "sorted_by_freq_tuples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpCjo_PDu2Hz",
        "outputId": "b9e7f426-09c1-485c-c8c7-480346dbb9c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('the', 16),\n",
              "             ('is', 9),\n",
              "             ('of', 7),\n",
              "             ('oz', 6),\n",
              "             ('and', 6),\n",
              "             ('to', 6),\n",
              "             ('it', 6),\n",
              "             ('i', 6),\n",
              "             ('with', 5),\n",
              "             ('for', 5),\n",
              "             ('that', 4),\n",
              "             ('as', 4),\n",
              "             ('me', 4),\n",
              "             ('violence', 4),\n",
              "             ('you', 3),\n",
              "             ('ll', 3),\n",
              "             ('this', 3),\n",
              "             ('was', 3),\n",
              "             ('in', 3),\n",
              "             ('not', 3),\n",
              "             ('a', 3),\n",
              "             ('show', 3),\n",
              "             ('or', 3),\n",
              "             ('on', 3),\n",
              "             ('prison', 3),\n",
              "             ('so', 3),\n",
              "             ('t', 3),\n",
              "             ('forget', 3),\n",
              "             ('other', 2),\n",
              "             ('watching', 2),\n",
              "             ('just', 2),\n",
              "             ('episode', 2),\n",
              "             ('be', 2),\n",
              "             ('are', 2),\n",
              "             ('right', 2),\n",
              "             ('what', 2),\n",
              "             ('first', 2),\n",
              "             ('struck', 2),\n",
              "             ('its', 2),\n",
              "             ('word', 2),\n",
              "             ('city', 2),\n",
              "             ('where', 2),\n",
              "             ('high', 2),\n",
              "             ('more', 2),\n",
              "             ('away', 2),\n",
              "             ('say', 2),\n",
              "             ('due', 2),\n",
              "             ('but', 2),\n",
              "             ('who', 2),\n",
              "             ('inmates', 2),\n",
              "             ('get', 2),\n",
              "             ('one', 1),\n",
              "             ('reviewers', 1),\n",
              "             ('has', 1),\n",
              "             ('mentioned', 1),\n",
              "             ('after', 1),\n",
              "             ('1', 1),\n",
              "             ('hooked', 1),\n",
              "             ('they', 1),\n",
              "             ('exactly', 1),\n",
              "             ('happened', 1),\n",
              "             ('thing', 1),\n",
              "             ('about', 1),\n",
              "             ('brutality', 1),\n",
              "             ('unflinching', 1),\n",
              "             ('scenes', 1),\n",
              "             ('which', 1),\n",
              "             ('set', 1),\n",
              "             ('from', 1),\n",
              "             ('go', 1),\n",
              "             ('trust', 1),\n",
              "             ('faint', 1),\n",
              "             ('hearted', 1),\n",
              "             ('timid', 1),\n",
              "             ('pulls', 1),\n",
              "             ('no', 1),\n",
              "             ('punches', 1),\n",
              "             ('regards', 1),\n",
              "             ('drugs', 1),\n",
              "             ('sex', 1),\n",
              "             ('hardcore', 1),\n",
              "             ('classic', 1),\n",
              "             ('use', 1),\n",
              "             ('called', 1),\n",
              "             ('nickname', 1),\n",
              "             ('given', 1),\n",
              "             ('oswald', 1),\n",
              "             ('maximum', 1),\n",
              "             ('security', 1),\n",
              "             ('state', 1),\n",
              "             ('penitentary', 1),\n",
              "             ('focuses', 1),\n",
              "             ('mainly', 1),\n",
              "             ('emerald', 1),\n",
              "             ('an', 1),\n",
              "             ('experimental', 1),\n",
              "             ('section', 1),\n",
              "             ('all', 1),\n",
              "             ('cells', 1),\n",
              "             ('have', 1),\n",
              "             ('glass', 1),\n",
              "             ('fronts', 1),\n",
              "             ('face', 1),\n",
              "             ('inwards', 1),\n",
              "             ('privacy', 1),\n",
              "             ('agenda', 1),\n",
              "             ('em', 1),\n",
              "             ('home', 1),\n",
              "             ('many', 1),\n",
              "             ('aryans', 1),\n",
              "             ('muslims', 1),\n",
              "             ('gangstas', 1),\n",
              "             ('latinos', 1),\n",
              "             ('christians', 1),\n",
              "             ('italians', 1),\n",
              "             ('irish', 1),\n",
              "             ('scuffles', 1),\n",
              "             ('death', 1),\n",
              "             ('stares', 1),\n",
              "             ('dodgy', 1),\n",
              "             ('dealings', 1),\n",
              "             ('shady', 1),\n",
              "             ('agreements', 1),\n",
              "             ('never', 1),\n",
              "             ('far', 1),\n",
              "             ('would', 1),\n",
              "             ('main', 1),\n",
              "             ('appeal', 1),\n",
              "             ('fact', 1),\n",
              "             ('goes', 1),\n",
              "             ('shows', 1),\n",
              "             ('wouldn', 1),\n",
              "             ('dare', 1),\n",
              "             ('pretty', 1),\n",
              "             ('pictures', 1),\n",
              "             ('painted', 1),\n",
              "             ('mainstream', 1),\n",
              "             ('audiences', 1),\n",
              "             ('charm', 1),\n",
              "             ('romance', 1),\n",
              "             ('doesn', 1),\n",
              "             ('mess', 1),\n",
              "             ('around', 1),\n",
              "             ('ever', 1),\n",
              "             ('saw', 1),\n",
              "             ('nasty', 1),\n",
              "             ('surreal', 1),\n",
              "             ('couldn', 1),\n",
              "             ('ready', 1),\n",
              "             ('watched', 1),\n",
              "             ('developed', 1),\n",
              "             ('taste', 1),\n",
              "             ('got', 1),\n",
              "             ('accustomed', 1),\n",
              "             ('levels', 1),\n",
              "             ('graphic', 1),\n",
              "             ('injustice', 1),\n",
              "             ('crooked', 1),\n",
              "             ('guards', 1),\n",
              "             ('sold', 1),\n",
              "             ('out', 1),\n",
              "             ('nickel', 1),\n",
              "             ('kill', 1),\n",
              "             ('order', 1),\n",
              "             ('well', 1),\n",
              "             ('mannered', 1),\n",
              "             ('middle', 1),\n",
              "             ('class', 1),\n",
              "             ('being', 1),\n",
              "             ('turned', 1),\n",
              "             ('into', 1),\n",
              "             ('bitches', 1),\n",
              "             ('their', 1),\n",
              "             ('lack', 1),\n",
              "             ('street', 1),\n",
              "             ('skills', 1),\n",
              "             ('experience', 1),\n",
              "             ('may', 1),\n",
              "             ('become', 1),\n",
              "             ('comfortable', 1),\n",
              "             ('uncomfortable', 1),\n",
              "             ('viewing', 1),\n",
              "             ('thats', 1),\n",
              "             ('if', 1),\n",
              "             ('can', 1),\n",
              "             ('touch', 1),\n",
              "             ('your', 1),\n",
              "             ('darker', 1),\n",
              "             ('side', 1)])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##\n",
        "# step 1: convert our sorted list of tokens to OrderedDict\n",
        "from collections import OrderedDict\n",
        "\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "ordered_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FpW-43Ru6m7",
        "outputId": "92453b73-a403-407d-e56f-9cfc6e5aa64c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "189"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##\n",
        "# Check the length of our dictionary\n",
        "len(ordered_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0C7UsUFu_VE",
        "outputId": "cc94e057-243d-4d70-d8a2-d86e0e052d6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'darker': 187,\n",
              " 'your': 186,\n",
              " 'touch': 185,\n",
              " 'thats': 182,\n",
              " 'uncomfortable': 180,\n",
              " 'experience': 176,\n",
              " 'skills': 175,\n",
              " 'street': 174,\n",
              " 'lack': 173,\n",
              " 'their': 172,\n",
              " 'bitches': 171,\n",
              " 'being': 168,\n",
              " 'may': 177,\n",
              " 'class': 167,\n",
              " 'mannered': 165,\n",
              " 'well': 164,\n",
              " 'order': 163,\n",
              " 'out': 160,\n",
              " 'guards': 158,\n",
              " 'levels': 154,\n",
              " 'got': 152,\n",
              " 'developed': 150,\n",
              " 'ready': 148,\n",
              " 'couldn': 147,\n",
              " 'surreal': 146,\n",
              " 'become': 178,\n",
              " 'saw': 144,\n",
              " 'ever': 143,\n",
              " 'comfortable': 179,\n",
              " 'around': 142,\n",
              " 'mess': 141,\n",
              " 'doesn': 140,\n",
              " 'romance': 139,\n",
              " 'charm': 138,\n",
              " 'audiences': 137,\n",
              " 'nickel': 161,\n",
              " 'pictures': 134,\n",
              " 'pretty': 133,\n",
              " 'dare': 132,\n",
              " 'kill': 162,\n",
              " 'wouldn': 131,\n",
              " 'goes': 129,\n",
              " 'appeal': 127,\n",
              " 'after': 55,\n",
              " 'more': 43,\n",
              " 'has': 53,\n",
              " 'inwards': 103,\n",
              " 'where': 41,\n",
              " 'say': 45,\n",
              " 'oz': 3,\n",
              " 'turned': 169,\n",
              " 'sold': 159,\n",
              " 'that': 10,\n",
              " 'what': 35,\n",
              " 'right': 34,\n",
              " 'one': 51,\n",
              " 'irish': 115,\n",
              " 'i': 7,\n",
              " 'pulls': 74,\n",
              " 'was': 17,\n",
              " 'scenes': 65,\n",
              " 'reviewers': 52,\n",
              " 'and': 4,\n",
              " 't': 26,\n",
              " 'maximum': 87,\n",
              " 'just': 30,\n",
              " 'many': 108,\n",
              " 'taste': 151,\n",
              " 'first': 36,\n",
              " 'as': 11,\n",
              " 'its': 38,\n",
              " 'on': 23,\n",
              " 'forget': 27,\n",
              " 'be': 32,\n",
              " 'focuses': 91,\n",
              " 'mentioned': 54,\n",
              " 'you': 14,\n",
              " 'not': 19,\n",
              " 'prison': 24,\n",
              " 'of': 2,\n",
              " 'classic': 81,\n",
              " '1': 56,\n",
              " 'violence': 13,\n",
              " 'this': 16,\n",
              " 'show': 21,\n",
              " 'struck': 37,\n",
              " 'is': 1,\n",
              " 'italians': 114,\n",
              " 'll': 15,\n",
              " 'hooked': 57,\n",
              " 'use': 82,\n",
              " 'fronts': 101,\n",
              " 'in': 18,\n",
              " 'side': 188,\n",
              " 'but': 47,\n",
              " 'with': 8,\n",
              " 'an': 94,\n",
              " 'muslims': 110,\n",
              " 'fact': 128,\n",
              " 'to': 5,\n",
              " 'state': 89,\n",
              " 'they': 58,\n",
              " 'glass': 100,\n",
              " 'mainly': 92,\n",
              " 'me': 12,\n",
              " 'due': 46,\n",
              " 'no': 75,\n",
              " 'watching': 29,\n",
              " 'hearted': 72,\n",
              " 'are': 33,\n",
              " 'or': 22,\n",
              " 'away': 44,\n",
              " 'it': 6,\n",
              " 'other': 28,\n",
              " 'get': 50,\n",
              " 'exactly': 59,\n",
              " 'trust': 70,\n",
              " 'crooked': 157,\n",
              " 'agreements': 122,\n",
              " 'thing': 61,\n",
              " 'about': 62,\n",
              " 'so': 25,\n",
              " 'brutality': 63,\n",
              " 'inmates': 49,\n",
              " 'city': 40,\n",
              " 'unflinching': 64,\n",
              " 'painted': 135,\n",
              " 'which': 66,\n",
              " 'shows': 130,\n",
              " 'set': 67,\n",
              " 'go': 69,\n",
              " 'regards': 77,\n",
              " 'aryans': 109,\n",
              " 'from': 68,\n",
              " 'faint': 71,\n",
              " 'injustice': 156,\n",
              " 'timid': 73,\n",
              " 'viewing': 181,\n",
              " 'high': 42,\n",
              " 'punches': 76,\n",
              " 'dealings': 120,\n",
              " 'main': 126,\n",
              " 'into': 170,\n",
              " 'drugs': 78,\n",
              " 'happened': 60,\n",
              " 'sex': 79,\n",
              " 'shady': 121,\n",
              " 'hardcore': 80,\n",
              " 'called': 83,\n",
              " 'nickname': 84,\n",
              " 'for': 9,\n",
              " 'oswald': 86,\n",
              " 'graphic': 155,\n",
              " 'home': 107,\n",
              " 'security': 88,\n",
              " 'nasty': 145,\n",
              " 'episode': 31,\n",
              " 'penitentary': 90,\n",
              " 'stares': 118,\n",
              " 'emerald': 93,\n",
              " 'experimental': 95,\n",
              " 'scuffles': 116,\n",
              " 'section': 96,\n",
              " 'all': 97,\n",
              " 'mainstream': 136,\n",
              " 'cells': 98,\n",
              " 'can': 184,\n",
              " 'have': 99,\n",
              " 'face': 102,\n",
              " 'accustomed': 153,\n",
              " 'who': 48,\n",
              " 'privacy': 104,\n",
              " 'watched': 149,\n",
              " 'agenda': 105,\n",
              " 'em': 106,\n",
              " 'middle': 166,\n",
              " 'word': 39,\n",
              " 'never': 123,\n",
              " 'gangstas': 111,\n",
              " 'a': 20,\n",
              " 'latinos': 112,\n",
              " 'christians': 113,\n",
              " 'death': 117,\n",
              " 'if': 183,\n",
              " 'dodgy': 119,\n",
              " 'far': 124,\n",
              " 'the': 0,\n",
              " 'given': 85,\n",
              " 'would': 125}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##\n",
        "# step 2: convert the ordered dict to torchtext.vocab\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "vb = vocab(ordered_dict)\n",
        "vb.get_stoi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "AU0M27UmwJLE",
        "outputId": "2d0a777c-ad3b-40fe-82c2-cbde74e57604"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.review[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukcW6aKlvFPU",
        "outputId": "eafaf634-e4a0-421f-fd19-f75c44ebeb14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "message vocab size: 94975\n"
          ]
        }
      ],
      "source": [
        "##\n",
        "# step 1: convert reviews into tokens\n",
        "# step 2: find frequency of tokens\n",
        "\n",
        "token_counts = Counter()\n",
        "\n",
        "for i in range(0,len(train_data)):\n",
        "    tokens = tokenizer(train_data['review'].iloc[i])\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "print('message vocab size:', len(token_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh8w-x8rWsWV",
        "outputId": "006b994f-e84b-40e6-b950-0e41ad834a2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'that': 115208,\n",
              "         's': 99834,\n",
              "         'what': 25950,\n",
              "         'i': 140753,\n",
              "         'kept': 1204,\n",
              "         'asking': 375,\n",
              "         'myself': 1848,\n",
              "         'during': 3442,\n",
              "         'the': 534382,\n",
              "         'many': 10733,\n",
              "         'fights': 435,\n",
              "         'screaming': 402,\n",
              "         'matches': 155,\n",
              "         'swearing': 89,\n",
              "         'and': 259123,\n",
              "         'general': 1211,\n",
              "         'mayhem': 134,\n",
              "         'permeate': 12,\n",
              "         '84': 33,\n",
              "         'minutes': 4692,\n",
              "         'comparisons': 95,\n",
              "         'also': 14435,\n",
              "         'stand': 1240,\n",
              "         'up': 20988,\n",
              "         'when': 22267,\n",
              "         'you': 55158,\n",
              "         'think': 11500,\n",
              "         'of': 231147,\n",
              "         'one': 42939,\n",
              "         'dimensional': 408,\n",
              "         'characters': 11485,\n",
              "         'who': 33815,\n",
              "         'have': 44185,\n",
              "         'so': 32758,\n",
              "         'little': 9924,\n",
              "         'depth': 808,\n",
              "         'it': 152778,\n",
              "         'is': 168846,\n",
              "         'virtually': 333,\n",
              "         'impossible': 763,\n",
              "         'to': 214267,\n",
              "         'care': 2209,\n",
              "         'happens': 1773,\n",
              "         'them': 12743,\n",
              "         'they': 36137,\n",
              "         'are': 46659,\n",
              "         'just': 28239,\n",
              "         'badly': 1041,\n",
              "         'written': 2525,\n",
              "         'cyphers': 7,\n",
              "         'for': 69839,\n",
              "         'director': 6998,\n",
              "         'hang': 250,\n",
              "         'his': 45842,\n",
              "         'multicultural': 4,\n",
              "         'beliefs': 153,\n",
              "         'on': 54419,\n",
              "         'a': 257772,\n",
              "         'topic': 254,\n",
              "         'has': 26491,\n",
              "         'been': 14678,\n",
              "         'done': 4934,\n",
              "         'much': 15402,\n",
              "         'better': 9120,\n",
              "         'in': 148900,\n",
              "         'other': 14483,\n",
              "         'dramas': 232,\n",
              "         'both': 5444,\n",
              "         'tv': 4550,\n",
              "         'cinema': 2325,\n",
              "         'must': 5241,\n",
              "         'confess': 130,\n",
              "         'm': 7997,\n",
              "         'not': 48730,\n",
              "         'really': 18445,\n",
              "         'spotting': 26,\n",
              "         'bad': 14824,\n",
              "         'performances': 2817,\n",
              "         'film': 63738,\n",
              "         'but': 66827,\n",
              "         'be': 42746,\n",
              "         'said': 3431,\n",
              "         'nichola': 1,\n",
              "         'burley': 3,\n",
              "         'as': 73393,\n",
              "         'heroine': 445,\n",
              "         'slutty': 46,\n",
              "         'best': 10136,\n",
              "         'friend': 2397,\n",
              "         'wasim': 2,\n",
              "         'zakir': 2,\n",
              "         'nasty': 504,\n",
              "         'bullying': 39,\n",
              "         'brother': 1690,\n",
              "         'were': 16928,\n",
              "         'absolutely': 2372,\n",
              "         'terrible': 2667,\n",
              "         'don': 14056,\n",
              "         't': 54355,\n",
              "         'know': 10006,\n",
              "         'acting': 10284,\n",
              "         'school': 2799,\n",
              "         'graduated': 36,\n",
              "         'from': 32561,\n",
              "         'if': 27162,\n",
              "         'was': 76533,\n",
              "         'd': 4719,\n",
              "         'apply': 83,\n",
              "         'full': 2839,\n",
              "         'refund': 34,\n",
              "         'post': 775,\n",
              "         'haste': 10,\n",
              "         'only': 18583,\n",
              "         'samina': 1,\n",
              "         'awan': 1,\n",
              "         'lead': 2150,\n",
              "         'role': 4956,\n",
              "         'manages': 924,\n",
              "         'impress': 163,\n",
              "         'cast': 5972,\n",
              "         'called': 2289,\n",
              "         'british': 1415,\n",
              "         'talent': 1579,\n",
              "         'we': 17087,\n",
              "         'll': 4658,\n",
              "         'probably': 4501,\n",
              "         'never': 10381,\n",
              "         'hear': 1139,\n",
              "         'again': 6373,\n",
              "         'at': 37511,\n",
              "         'least': 4938,\n",
              "         'hope': 2345,\n",
              "         'next': 2806,\n",
              "         'time': 20109,\n",
              "         'hire': 185,\n",
              "         'different': 3727,\n",
              "         'scout': 45,\n",
              "         'another': 6791,\n",
              "         'intriguing': 497,\n",
              "         'thought': 5596,\n",
              "         'hideously': 37,\n",
              "         'fashionable': 38,\n",
              "         'soundtrack': 1325,\n",
              "         'featuring': 426,\n",
              "         'likes': 756,\n",
              "         'snow': 261,\n",
              "         'patrol': 38,\n",
              "         'ian': 187,\n",
              "         'brown': 503,\n",
              "         'keane': 5,\n",
              "         'now': 7386,\n",
              "         'bit': 4685,\n",
              "         'music': 5149,\n",
              "         'fan': 3171,\n",
              "         'familiar': 851,\n",
              "         'with': 69602,\n",
              "         'most': 13869,\n",
              "         'these': 8519,\n",
              "         'artists': 267,\n",
              "         'output': 58,\n",
              "         'didn': 7021,\n",
              "         'recognise': 53,\n",
              "         'any': 12002,\n",
              "         'tracks': 170,\n",
              "         'this': 120630,\n",
              "         'movie': 70138,\n",
              "         'apart': 945,\n",
              "         'omnipresent': 20,\n",
              "         'run': 1996,\n",
              "         'b': 2049,\n",
              "         'sides': 296,\n",
              "         'anyone': 4304,\n",
              "         'get': 14649,\n",
              "         'musical': 1420,\n",
              "         'montages': 47,\n",
              "         'which': 18696,\n",
              "         'telegraph': 32,\n",
              "         'how': 14090,\n",
              "         're': 7095,\n",
              "         'suppose': 653,\n",
              "         'feel': 4704,\n",
              "         'accompanied': 153,\n",
              "         'by': 35485,\n",
              "         'such': 8010,\n",
              "         'startlingly': 18,\n",
              "         'original': 5109,\n",
              "         'images': 794,\n",
              "         'couples': 152,\n",
              "         'kissing': 118,\n",
              "         'swollen': 9,\n",
              "         'lake': 343,\n",
              "         'canoodling': 2,\n",
              "         'doorways': 6,\n",
              "         'problem': 2274,\n",
              "         'none': 1574,\n",
              "         'songs': 1351,\n",
              "         'convey': 252,\n",
              "         'mood': 700,\n",
              "         'efficiently': 21,\n",
              "         'realise': 193,\n",
              "         'lacks': 571,\n",
              "         'ability': 726,\n",
              "         'carry': 531,\n",
              "         'emotional': 1096,\n",
              "         'journey': 718,\n",
              "         'audience': 3464,\n",
              "         'through': 7826,\n",
              "         'storytelling': 260,\n",
              "         'dialogue': 2467,\n",
              "         'alone': 1564,\n",
              "         'ending': 3827,\n",
              "         'presumably': 197,\n",
              "         'meant': 944,\n",
              "         'desserts': 29,\n",
              "         'everybody': 707,\n",
              "         'gets': 4951,\n",
              "         'their': 18134,\n",
              "         'comeuppance': 18,\n",
              "         'there': 30000,\n",
              "         'big': 5560,\n",
              "         'shock': 593,\n",
              "         'store': 839,\n",
              "         'remained': 131,\n",
              "         'resolutely': 13,\n",
              "         'unmoved': 7,\n",
              "         'because': 14076,\n",
              "         'script': 4748,\n",
              "         'had': 17594,\n",
              "         'given': 2854,\n",
              "         'me': 17293,\n",
              "         'no': 20181,\n",
              "         'root': 195,\n",
              "         'enough': 5536,\n",
              "         'tackle': 63,\n",
              "         'hot': 1097,\n",
              "         'button': 202,\n",
              "         'issue': 479,\n",
              "         'actually': 6782,\n",
              "         'give': 5388,\n",
              "         'us': 5923,\n",
              "         'plot': 10467,\n",
              "         'hasn': 525,\n",
              "         'already': 2140,\n",
              "         'death': 3168,\n",
              "         'individuals': 202,\n",
              "         'more': 22347,\n",
              "         'than': 15424,\n",
              "         'window': 441,\n",
              "         'dressing': 138,\n",
              "         'stands': 635,\n",
              "         'noble': 200,\n",
              "         'failure': 403,\n",
              "         'promising': 322,\n",
              "         'actress': 1874,\n",
              "         'few': 6359,\n",
              "         'mildly': 302,\n",
              "         'diverting': 18,\n",
              "         'punch': 279,\n",
              "         'ups': 472,\n",
              "         'save': 1675,\n",
              "         'bin': 183,\n",
              "         '4': 2238,\n",
              "         '10': 6805,\n",
              "         'try': 2908,\n",
              "         'harder': 179,\n",
              "         'did': 10133,\n",
              "         'watch': 11186,\n",
              "         'entire': 2286,\n",
              "         'could': 12565,\n",
              "         'stopped': 347,\n",
              "         'dvd': 3953,\n",
              "         'after': 11894,\n",
              "         'watching': 7369,\n",
              "         'half': 3441,\n",
              "         'an': 34438,\n",
              "         'hour': 1871,\n",
              "         'suggest': 594,\n",
              "         'thinking': 1841,\n",
              "         'themselves': 1897,\n",
              "         'stop': 1834,\n",
              "         'before': 6756,\n",
              "         'taking': 1523,\n",
              "         'disc': 192,\n",
              "         'out': 27374,\n",
              "         'case': 2435,\n",
              "         'like': 32078,\n",
              "         'mafia': 175,\n",
              "         'movies': 12331,\n",
              "         'tragic': 519,\n",
              "         'comic': 1278,\n",
              "         'corky': 36,\n",
              "         'romano': 30,\n",
              "         'can': 23061,\n",
              "         'described': 384,\n",
              "         'attempt': 1640,\n",
              "         'comedy': 5128,\n",
              "         'simply': 3072,\n",
              "         'tries': 1945,\n",
              "         'too': 12244,\n",
              "         'hard': 4239,\n",
              "         'laugh': 2376,\n",
              "         'seems': 5715,\n",
              "         'excuse': 643,\n",
              "         'moving': 1367,\n",
              "         'chris': 690,\n",
              "         'kattan': 22,\n",
              "         'scene': 8843,\n",
              "         'himself': 3380,\n",
              "         'completely': 3052,\n",
              "         'overplayed': 35,\n",
              "         'subtlety': 165,\n",
              "         'or': 28549,\n",
              "         'credulity': 18,\n",
              "         'all': 37572,\n",
              "         'strange': 1465,\n",
              "         'mannerisms': 89,\n",
              "         'come': 5029,\n",
              "         'across': 1577,\n",
              "         'contrived': 388,\n",
              "         'clearly': 1385,\n",
              "         'rather': 4185,\n",
              "         'bounces': 29,\n",
              "         'right': 5196,\n",
              "         'story': 18590,\n",
              "         'each': 4113,\n",
              "         'utterly': 677,\n",
              "         'predictable': 1360,\n",
              "         'comedic': 499,\n",
              "         'event': 539,\n",
              "         'will': 14415,\n",
              "         'occur': 185,\n",
              "         'set': 3834,\n",
              "         'obvious': 1678,\n",
              "         'soon': 1866,\n",
              "         'introduced': 492,\n",
              "         'comedies': 652,\n",
              "         'mr': 2275,\n",
              "         'bean': 140,\n",
              "         'disasters': 54,\n",
              "         'caused': 382,\n",
              "         'title': 2401,\n",
              "         'character': 11122,\n",
              "         'funny': 6958,\n",
              "         'empathise': 14,\n",
              "         'motivations': 137,\n",
              "         'initial': 304,\n",
              "         'situation': 1094,\n",
              "         'ends': 1506,\n",
              "         'telegraphed': 27,\n",
              "         'however': 5589,\n",
              "         'gives': 2478,\n",
              "         'feeling': 1723,\n",
              "         'he': 46631,\n",
              "         'deliberately': 152,\n",
              "         'screwing': 37,\n",
              "         'desperate': 448,\n",
              "         'draw': 318,\n",
              "         'played': 4110,\n",
              "         'alien': 835,\n",
              "         'connects': 42,\n",
              "         'whose': 1527,\n",
              "         'behaviour': 133,\n",
              "         'entirely': 824,\n",
              "         'inexplicable': 83,\n",
              "         'except': 1773,\n",
              "         'trying': 3922,\n",
              "         'laughs': 1034,\n",
              "         'scenes': 8381,\n",
              "         'weren': 754,\n",
              "         'stereotyped': 76,\n",
              "         'jokes': 1590,\n",
              "         'seemed': 2182,\n",
              "         'far': 4845,\n",
              "         'watchable': 493,\n",
              "         'isn': 5019,\n",
              "         'touching': 667,\n",
              "         'love': 10349,\n",
              "         'reminiscent': 267,\n",
              "         'drawing': 144,\n",
              "         'heavily': 299,\n",
              "         'chinese': 498,\n",
              "         'poetry': 175,\n",
              "         'used': 3093,\n",
              "         'eastern': 161,\n",
              "         'people': 14525,\n",
              "         'communicate': 106,\n",
              "         'feelings': 658,\n",
              "         'focuses': 278,\n",
              "         'schoolteacher': 19,\n",
              "         'wants': 2014,\n",
              "         'model': 362,\n",
              "         'teacher': 529,\n",
              "         'well': 17101,\n",
              "         'good': 23688,\n",
              "         'husband': 1631,\n",
              "         'father': 3153,\n",
              "         'senior': 84,\n",
              "         'student': 658,\n",
              "         'very': 22327,\n",
              "         'attracted': 199,\n",
              "         'him': 14035,\n",
              "         'unfolds': 161,\n",
              "         'see': 18381,\n",
              "         'emotions': 667,\n",
              "         'below': 473,\n",
              "         'surface': 345,\n",
              "         '20': 1172,\n",
              "         'year': 3591,\n",
              "         'marriage': 569,\n",
              "         'grapples': 5,\n",
              "         'moral': 567,\n",
              "         'dilemmas': 34,\n",
              "         'face': 2569,\n",
              "         'beautiful': 3357,\n",
              "         'latter': 544,\n",
              "         'day': 4175,\n",
              "         'fulci': 288,\n",
              "         'schlocker': 3,\n",
              "         'totally': 2231,\n",
              "         'abysmal': 150,\n",
              "         'concoction': 30,\n",
              "         'dealing': 433,\n",
              "         'incurable': 7,\n",
              "         'gambler': 36,\n",
              "         'brett': 71,\n",
              "         'halsey': 12,\n",
              "         'decides': 843,\n",
              "         'bluebeard': 9,\n",
              "         'style': 2559,\n",
              "         'pay': 953,\n",
              "         'off': 9635,\n",
              "         'ever': 9676,\n",
              "         'rising': 159,\n",
              "         'debts': 33,\n",
              "         'seducing': 43,\n",
              "         'some': 24924,\n",
              "         'ugliest': 22,\n",
              "         'bitches': 16,\n",
              "         'lay': 163,\n",
              "         'your': 9161,\n",
              "         'eyes': 1929,\n",
              "         'happen': 1705,\n",
              "         'wealthy': 261,\n",
              "         'widows': 21,\n",
              "         'penned': 59,\n",
              "         'contrives': 12,\n",
              "         'incorporate': 42,\n",
              "         'blackly': 6,\n",
              "         'elements': 1218,\n",
              "         'result': 1010,\n",
              "         'unfunny': 407,\n",
              "         'business': 975,\n",
              "         'involving': 763,\n",
              "         'corpse': 208,\n",
              "         'won': 2623,\n",
              "         'stay': 1250,\n",
              "         'put': 3819,\n",
              "         'opera': 660,\n",
              "         'singer': 472,\n",
              "         'victim': 655,\n",
              "         'singing': 788,\n",
              "         'etc': 1968,\n",
              "         'mention': 1280,\n",
              "         'doppelganger': 30,\n",
              "         'theme': 1269,\n",
              "         'straight': 1356,\n",
              "         'prague': 23,\n",
              "         'although': 4029,\n",
              "         'two': 10807,\n",
              "         'personas': 18,\n",
              "         'via': 285,\n",
              "         'pre': 471,\n",
              "         'recorded': 179,\n",
              "         'radio': 597,\n",
              "         'messages': 197,\n",
              "         'end': 8990,\n",
              "         'say': 8574,\n",
              "         'surprised': 1261,\n",
              "         'shows': 3792,\n",
              "         'sign': 407,\n",
              "         'sophistication': 59,\n",
              "         'mario': 190,\n",
              "         'bava': 68,\n",
              "         'hatchet': 36,\n",
              "         'honeymoon': 48,\n",
              "         '1970': 286,\n",
              "         'resembles': 184,\n",
              "         'several': 2310,\n",
              "         'ways': 1256,\n",
              "         'content': 594,\n",
              "         'merely': 539,\n",
              "         'pile': 300,\n",
              "         'disgustingly': 23,\n",
              "         'gory': 393,\n",
              "         'convincing': 841,\n",
              "         'effects': 3704,\n",
              "         'dismembered': 16,\n",
              "         'limbs': 52,\n",
              "         'squashed': 14,\n",
              "         'melting': 109,\n",
              "         'faces': 600,\n",
              "         'alas': 244,\n",
              "         'then': 12764,\n",
              "         'become': 2317,\n",
              "         'associated': 202,\n",
              "         'first': 14056,\n",
              "         'firmly': 113,\n",
              "         'believe': 3988,\n",
              "         'norwegian': 66,\n",
              "         'continually': 113,\n",
              "         'getting': 2596,\n",
              "         'tedious': 347,\n",
              "         'films': 10902,\n",
              "         '70': 674,\n",
              "         '80': 1034,\n",
              "         'place': 3785,\n",
              "         'started': 1525,\n",
              "         'contain': 249,\n",
              "         'humour': 761,\n",
              "         'imagine': 1171,\n",
              "         'actual': 1180,\n",
              "         'made': 12915,\n",
              "         'starting': 450,\n",
              "         'entertaining': 2339,\n",
              "         'opposed': 204,\n",
              "         'long': 5557,\n",
              "         'dark': 2211,\n",
              "         'depressing': 353,\n",
              "         'boring': 2963,\n",
              "         '90': 834,\n",
              "         '00': 172,\n",
              "         'great': 14519,\n",
              "         'new': 6445,\n",
              "         'generation': 459,\n",
              "         'filmmakers': 894,\n",
              "         'praised': 88,\n",
              "         'critics': 623,\n",
              "         'loads': 164,\n",
              "         'money': 3595,\n",
              "         'became': 1060,\n",
              "         'norm': 102,\n",
              "         'came': 2652,\n",
              "         'united': 357,\n",
              "         'minor': 640,\n",
              "         'spoilers': 865,\n",
              "         'once': 3695,\n",
              "         'thing': 7322,\n",
              "         'its': 12711,\n",
              "         'especially': 3945,\n",
              "         'comedians': 132,\n",
              "         'neither': 808,\n",
              "         'nor': 1015,\n",
              "         'do': 14639,\n",
              "         'anything': 4610,\n",
              "         'where': 10197,\n",
              "         'humor': 2186,\n",
              "         'show': 9974,\n",
              "         'awkward': 400,\n",
              "         'clerk': 80,\n",
              "         'harald': 7,\n",
              "         'eia': 1,\n",
              "         'overacting': 138,\n",
              "         'ridiculously': 185,\n",
              "         'unrealistic': 387,\n",
              "         'football': 406,\n",
              "         'coach': 250,\n",
              "         'commentaries': 49,\n",
              "         'arne': 6,\n",
              "         'scheie': 1,\n",
              "         'thats': 547,\n",
              "         'my': 19973,\n",
              "         'main': 3722,\n",
              "         'rant': 59,\n",
              "         'about': 27304,\n",
              "         'namely': 167,\n",
              "         'predictability': 49,\n",
              "         'here': 8808,\n",
              "         'fear': 834,\n",
              "         'standstill': 5,\n",
              "         'since': 4587,\n",
              "         'seen': 10824,\n",
              "         'going': 6637,\n",
              "         'exactly': 1541,\n",
              "         'presented': 649,\n",
              "         'start': 2696,\n",
              "         'deserve': 479,\n",
              "         'room': 1466,\n",
              "         'surprises': 309,\n",
              "         'sat': 464,\n",
              "         'seeing': 3358,\n",
              "         'realize': 991,\n",
              "         'need': 2856,\n",
              "         'blood': 1789,\n",
              "         'making': 4665,\n",
              "         'rating': 1486,\n",
              "         '1': 3463,\n",
              "         '6': 909,\n",
              "         'received': 418,\n",
              "         'positive': 793,\n",
              "         'reviews': 1176,\n",
              "         'site': 398,\n",
              "         'vonnegut': 39,\n",
              "         'am': 4584,\n",
              "         'showtime': 93,\n",
              "         'bastardized': 7,\n",
              "         'beyond': 1486,\n",
              "         'belief': 297,\n",
              "         'even': 19830,\n",
              "         'wasn': 3590,\n",
              "         'poor': 3085,\n",
              "         'casting': 879,\n",
              "         'sean': 447,\n",
              "         'astin': 40,\n",
              "         'brilliant': 1929,\n",
              "         'athletic': 61,\n",
              "         'around': 5746,\n",
              "         'individual': 398,\n",
              "         'harrison': 123,\n",
              "         'guy': 5080,\n",
              "         'generic': 177,\n",
              "         'sub': 652,\n",
              "         'standard': 723,\n",
              "         'writing': 2045,\n",
              "         'rendered': 112,\n",
              "         'tripe': 151,\n",
              "         'barely': 772,\n",
              "         'someone': 3665,\n",
              "         'pointed': 209,\n",
              "         'cute': 915,\n",
              "         'maculay': 1,\n",
              "         'culkin': 38,\n",
              "         'line': 2923,\n",
              "         'read': 3021,\n",
              "         'pure': 877,\n",
              "         'brilliance': 196,\n",
              "         'sadly': 878,\n",
              "         'intentionally': 127,\n",
              "         'part': 6278,\n",
              "         'maybe': 3792,\n",
              "         'insane': 397,\n",
              "         'please': 1649,\n",
              "         'nightmare': 427,\n",
              "         'weekend': 309,\n",
              "         'stars': 2537,\n",
              "         'ridiculous': 1522,\n",
              "         'actors': 7111,\n",
              "         'less': 2968,\n",
              "         'idea': 3184,\n",
              "         'decipherable': 3,\n",
              "         'special': 3488,\n",
              "         'joke': 990,\n",
              "         'sound': 2292,\n",
              "         'directed': 1913,\n",
              "         'henry': 554,\n",
              "         'sala': 3,\n",
              "         'reason': 3613,\n",
              "         'spoiler': 675,\n",
              "         'alert': 134,\n",
              "         'soooo': 38,\n",
              "         'arnie': 64,\n",
              "         'incident': 214,\n",
              "         'fighting': 917,\n",
              "         'helicopter': 166,\n",
              "         'disobeying': 6,\n",
              "         'orders': 174,\n",
              "         'sent': 635,\n",
              "         'jail': 301,\n",
              "         'sort': 2369,\n",
              "         'work': 6755,\n",
              "         'camp': 751,\n",
              "         'escapes': 248,\n",
              "         'short': 3108,\n",
              "         'while': 8296,\n",
              "         'caught': 923,\n",
              "         'freakish': 19,\n",
              "         'reality': 1563,\n",
              "         'supposed': 2288,\n",
              "         'bunch': 1269,\n",
              "         'tough': 718,\n",
              "         'guys': 2275,\n",
              "         'themes': 612,\n",
              "         'eventually': 1106,\n",
              "         'die': 1335,\n",
              "         'tougher': 23,\n",
              "         'toughest': 22,\n",
              "         'wanted': 2184,\n",
              "         'being': 10554,\n",
              "         'running': 1533,\n",
              "         'man': 9379,\n",
              "         'contains': 644,\n",
              "         'flaws': 567,\n",
              "         'annoy': 58,\n",
              "         'crap': 1682,\n",
              "         'e': 1046,\n",
              "         'g': 672,\n",
              "         'reconstruction': 18,\n",
              "         'fight': 1751,\n",
              "         'inside': 1024,\n",
              "         'shocked': 356,\n",
              "         'showed': 754,\n",
              "         'summary': 294,\n",
              "         'complete': 1646,\n",
              "         '5': 2271,\n",
              "         'camera': 2868,\n",
              "         'angles': 322,\n",
              "         'means': 1200,\n",
              "         'military': 712,\n",
              "         'flew': 61,\n",
              "         'equipped': 42,\n",
              "         'almost': 5014,\n",
              "         'cameras': 173,\n",
              "         'filming': 635,\n",
              "         'crew': 1107,\n",
              "         'members': 910,\n",
              "         '_inside_': 1,\n",
              "         'eye': 1280,\n",
              "         'beats': 187,\n",
              "         'theory': 289,\n",
              "         'interesting': 4930,\n",
              "         'innovative': 163,\n",
              "         'works': 1960,\n",
              "         'creates': 360,\n",
              "         'pool': 233,\n",
              "         'stupidness': 2,\n",
              "         'unrealism': 4,\n",
              "         'drowns': 30,\n",
              "         'par': 353,\n",
              "         'leading': 929,\n",
              "         'doing': 2497,\n",
              "         'average': 1134,\n",
              "         'performance': 4441,\n",
              "         'rest': 2811,\n",
              "         'without': 5178,\n",
              "         'ok': 1707,\n",
              "         'impressive': 785,\n",
              "         '3': 3071,\n",
              "         'mouthing': 12,\n",
              "         'those': 7501,\n",
              "         'understand': 2621,\n",
              "         'begin': 1059,\n",
              "         'blockbusters': 66,\n",
              "         'adverse': 16,\n",
              "         'doesn': 7099,\n",
              "         'star': 3193,\n",
              "         'leonardo': 44,\n",
              "         'dicaprio': 36,\n",
              "         'wilder': 104,\n",
              "         'napalm': 17,\n",
              "         'neat': 206,\n",
              "         'may': 5312,\n",
              "         'seem': 3364,\n",
              "         'quirky': 285,\n",
              "         'stupid': 2794,\n",
              "         'makes': 6675,\n",
              "         'substance': 333,\n",
              "         'particular': 1137,\n",
              "         'impressed': 566,\n",
              "         'use': 2842,\n",
              "         'plays': 3412,\n",
              "         'large': 915,\n",
              "         'students': 594,\n",
              "         'notice': 640,\n",
              "         'important': 1505,\n",
              "         'vida': 14,\n",
              "         'life': 10347,\n",
              "         'background': 1021,\n",
              "         'wallace': 193,\n",
              "         'heard': 1815,\n",
              "         'opening': 1599,\n",
              "         'sequence': 1354,\n",
              "         'lyrics': 172,\n",
              "         'play': 3569,\n",
              "         'instance': 409,\n",
              "         'men': 3055,\n",
              "         'duke': 193,\n",
              "         'earl': 126,\n",
              "         'sing': 412,\n",
              "         'something': 8105,\n",
              "         'she': 21742,\n",
              "         'girl': 4390,\n",
              "         'goes': 3803,\n",
              "         'over': 9792,\n",
              "         'lyric': 19,\n",
              "         'cleverly': 141,\n",
              "         'showing': 1259,\n",
              "         'tension': 813,\n",
              "         'between': 5154,\n",
              "         'brothers': 840,\n",
              "         'sorts': 305,\n",
              "         'intricacies': 21,\n",
              "         'look': 6653,\n",
              "         'flop': 156,\n",
              "         'outside': 959,\n",
              "         'real': 7568,\n",
              "         'usual': 1455,\n",
              "         'looking': 4029,\n",
              "         'forward': 1038,\n",
              "         'favourite': 506,\n",
              "         'subject': 1280,\n",
              "         'mine': 487,\n",
              "         'nice': 3096,\n",
              "         'change': 1494,\n",
              "         'strangely': 268,\n",
              "         'documentary': 1552,\n",
              "         'kursk': 1,\n",
              "         'stalingrad': 64,\n",
              "         'history': 2076,\n",
              "         'channel': 761,\n",
              "         'avidly': 6,\n",
              "         'looked': 1665,\n",
              "         'pearl': 171,\n",
              "         'harbour': 18,\n",
              "         'enemy': 381,\n",
              "         'gates': 92,\n",
              "         'rudely': 13,\n",
              "         'brought': 1183,\n",
              "         'down': 5919,\n",
              "         'earth': 1389,\n",
              "         'realisation': 17,\n",
              "         'malevolent': 38,\n",
              "         'ifying': 1,\n",
              "         'power': 1514,\n",
              "         'hollywood': 2897,\n",
              "         'spend': 802,\n",
              "         'absolute': 547,\n",
              "         'fortune': 198,\n",
              "         'yet': 4333,\n",
              "         'got': 5599,\n",
              "         'excited': 358,\n",
              "         'rise': 350,\n",
              "         'evil': 2164,\n",
              "         'kershaw': 8,\n",
              "         'involved': 1688,\n",
              "         've': 8175,\n",
              "         'enjoyed': 1969,\n",
              "         'books': 739,\n",
              "         'why': 8329,\n",
              "         'quit': 137,\n",
              "         'quote': 235,\n",
              "         'responsible': 454,\n",
              "         'rubbish': 433,\n",
              "         'book': 3765,\n",
              "         'academic': 58,\n",
              "         'piece': 2405,\n",
              "         'wasquite': 1,\n",
              "         'dry': 334,\n",
              "         'needed': 1079,\n",
              "         'incidents': 98,\n",
              "         'nuts': 130,\n",
              "         'hitler': 402,\n",
              "         'cannot': 1686,\n",
              "         'yes': 2349,\n",
              "         'volume': 107,\n",
              "         'biographies': 23,\n",
              "         'detailed': 191,\n",
              "         'thesis': 26,\n",
              "         'behind': 1951,\n",
              "         'hated': 469,\n",
              "         'jews': 150,\n",
              "         'miss': 1430,\n",
              "         'emphasise': 8,\n",
              "         'fact': 5545,\n",
              "         'every': 6359,\n",
              "         'effort': 1245,\n",
              "         'whatsoever': 531,\n",
              "         'explain': 731,\n",
              "         'adopted': 111,\n",
              "         'views': 260,\n",
              "         'strategy': 44,\n",
              "         'needless': 229,\n",
              "         'unlike': 900,\n",
              "         'generally': 685,\n",
              "         'excellent': 3322,\n",
              "         'nazis': 202,\n",
              "         'warning': 479,\n",
              "         'neglected': 73,\n",
              "         'point': 4955,\n",
              "         'nearly': 1217,\n",
              "         'leaders': 89,\n",
              "         'munich': 31,\n",
              "         'communist': 155,\n",
              "         'jewish': 316,\n",
              "         'coloured': 18,\n",
              "         'axiomatic': 1,\n",
              "         'linking': 22,\n",
              "         'bolshevism': 2,\n",
              "         'crucial': 157,\n",
              "         'aspect': 717,\n",
              "         'understanding': 479,\n",
              "         'nazi': 288,\n",
              "         'era': 936,\n",
              "         'makers': 761,\n",
              "         'go': 7991,\n",
              "         'stuff': 1869,\n",
              "         'knew': 1454,\n",
              "         'anyway': 1812,\n",
              "         'certainly': 2381,\n",
              "         'fascinating': 596,\n",
              "         'alludes': 13,\n",
              "         'briefly': 209,\n",
              "         'socialist': 37,\n",
              "         'immediately': 754,\n",
              "         'ww1': 13,\n",
              "         'would': 19696,\n",
              "         'course': 3889,\n",
              "         'complex': 679,\n",
              "         'handle': 272,\n",
              "         'might': 4603,\n",
              "         'detract': 85,\n",
              "         'relentless': 88,\n",
              "         'mantra': 19,\n",
              "         'bangs': 27,\n",
              "         'away': 4430,\n",
              "         'incessantly': 25,\n",
              "         'mesmerising': 20,\n",
              "         'figure': 1149,\n",
              "         'public': 891,\n",
              "         'speaker': 42,\n",
              "         'private': 399,\n",
              "         'situations': 804,\n",
              "         'polite': 52,\n",
              "         'sympathetic': 381,\n",
              "         'espoused': 7,\n",
              "         'vegetarianism': 2,\n",
              "         'anti': 835,\n",
              "         'alcohol': 139,\n",
              "         'smoking': 225,\n",
              "         'guardian': 69,\n",
              "         'readers': 100,\n",
              "         'agree': 938,\n",
              "         'famously': 24,\n",
              "         'fond': 169,\n",
              "         'animals': 556,\n",
              "         'hence': 245,\n",
              "         'wholly': 111,\n",
              "         'invented': 117,\n",
              "         'dog': 1180,\n",
              "         'flogging': 6,\n",
              "         'absurd': 474,\n",
              "         'accounts': 100,\n",
              "         'brave': 277,\n",
              "         'soldier': 529,\n",
              "         'whilst': 448,\n",
              "         'saw': 5043,\n",
              "         'iron': 170,\n",
              "         'cross': 538,\n",
              "         'acts': 636,\n",
              "         'bravery': 53,\n",
              "         'insight': 295,\n",
              "         'into': 14256,\n",
              "         'fired': 177,\n",
              "         'war': 3528,\n",
              "         'experiences': 312,\n",
              "         'sassoon': 2,\n",
              "         'owen': 187,\n",
              "         'brook': 27,\n",
              "         'remarque': 5,\n",
              "         'others': 2541,\n",
              "         'found': 4138,\n",
              "         'repellent': 38,\n",
              "         'experience': 1721,\n",
              "         'above': 1323,\n",
              "         'bolshevik': 7,\n",
              "         'link': 156,\n",
              "         'vital': 115,\n",
              "         'always': 5043,\n",
              "         'despite': 2137,\n",
              "         'massive': 304,\n",
              "         'evidence': 398,\n",
              "         'contrary': 179,\n",
              "         'colleagues': 87,\n",
              "         'died': 854,\n",
              "         'still': 8635,\n",
              "         'drew': 297,\n",
              "         'wrong': 2847,\n",
              "         'conclusions': 66,\n",
              "         'interest': 1607,\n",
              "         'either': 2977,\n",
              "         'often': 2486,\n",
              "         'days': 2084,\n",
              "         'classic': 2854,\n",
              "         'example': 2135,\n",
              "         'relevant': 211,\n",
              "         'present': 962,\n",
              "         'inventing': 31,\n",
              "         'leaving': 778,\n",
              "         'facts': 376,\n",
              "         'fit': 821,\n",
              "         'cater': 23,\n",
              "         'lowest': 145,\n",
              "         'common': 819,\n",
              "         'denominator': 39,\n",
              "         'trust': 487,\n",
              "         'inch': 74,\n",
              "         'ram': 65,\n",
              "         'throats': 59,\n",
              "         'knowing': 666,\n",
              "         'correctly': 133,\n",
              "         'dumb': 1014,\n",
              "         'fools': 100,\n",
              "         ...})"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S57k9mTkxadg",
        "outputId": "5b658067-7c8f-41fb-f61f-02bd60f09bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this  -->  11\n",
            "is  -->  7\n",
            "an  -->  35\n",
            "example  -->  472\n"
          ]
        }
      ],
      "source": [
        "##\n",
        "# step 3: sort the token based on their frequency\n",
        "# step 4: put the sorted tokens in OrderedDict\n",
        "# step 5: convert token to integers using vocab object\n",
        "\n",
        "sorted_by_freq_tuples = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "\n",
        "vb = vocab(ordered_dict)\n",
        "\n",
        "vb.insert_token(\"<pad>\", 0)  # special token for padding\n",
        "vb.insert_token(\"<unk>\", 1)  # special token for unknown words\n",
        "vb.set_default_index(1)\n",
        "\n",
        "# print some token indexes from vocab\n",
        "for token in [\"this\", \"is\", \"an\", \"example\"]:\n",
        "    print(token, \" --> \", vb[token])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb90FVVcxsLZ",
        "outputId": "d6ebcd5e-8214-4cf8-9d5c-4a8736be0e19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "94977"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vb.get_itos())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24J8htR9xwGD",
        "outputId": "c560e258-fb4c-41ce-f682-6d9fa2405b3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<pad>', '<unk>', 'the', 'and', 'a', 'of', 'to', 'is', 'it', 'in']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vb.get_itos()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NZba6itKyQW-",
        "outputId": "0792c4e5-1e1c-4b9d-9024-7e0b1afb77d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'when'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vb.get_itos()[54]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrjbsaKex5Jj",
        "outputId": "cd4b5e7a-c7a6-4b89-cc49-2df2b452e39e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['unarticulated',\n",
              " 'catfighting',\n",
              " 'smethurst',\n",
              " 'villein',\n",
              " 'tine',\n",
              " 'trustment',\n",
              " 'coooool',\n",
              " 'tunnelful',\n",
              " 'hieronymus',\n",
              " 'wilshire']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vb.get_itos()[-10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TLY-Apnux7hj"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# inline lambda functions for text and label precessing\n",
        "text_pipeline = lambda x: [vb[token] for token in tokenizer(x)]\n",
        "label_pipeline = lambda x: 1.0 if x == \"positive\" else 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "G_wFzAJyyKnf",
        "outputId": "18ebf5f2-37cd-4a53-c310-be09b9488797"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZAmlB-QyGuV",
        "outputId": "a4ec3c3e-7b8e-47ca-93ad-d8cd28d06c1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[29,\n",
              " 5,\n",
              " 2,\n",
              " 81,\n",
              " 2074,\n",
              " 47,\n",
              " 1060,\n",
              " 12,\n",
              " 101,\n",
              " 149,\n",
              " 42,\n",
              " 303,\n",
              " 3058,\n",
              " 391,\n",
              " 21,\n",
              " 233,\n",
              " 30,\n",
              " 3311,\n",
              " 33,\n",
              " 25,\n",
              " 204,\n",
              " 15,\n",
              " 11,\n",
              " 7,\n",
              " 632,\n",
              " 48,\n",
              " 595,\n",
              " 18,\n",
              " 69,\n",
              " 2,\n",
              " 88,\n",
              " 150,\n",
              " 12,\n",
              " 3149,\n",
              " 69,\n",
              " 45,\n",
              " 3058,\n",
              " 14,\n",
              " 94,\n",
              " 5742,\n",
              " 3,\n",
              " 14741,\n",
              " 135,\n",
              " 5,\n",
              " 571,\n",
              " 62,\n",
              " 268,\n",
              " 9,\n",
              " 204,\n",
              " 38,\n",
              " 2,\n",
              " 651,\n",
              " 142,\n",
              " 1734,\n",
              " 69,\n",
              " 11,\n",
              " 7,\n",
              " 24,\n",
              " 4,\n",
              " 120,\n",
              " 17,\n",
              " 2,\n",
              " 7797,\n",
              " 2238,\n",
              " 41,\n",
              " 11502,\n",
              " 11,\n",
              " 120,\n",
              " 2621,\n",
              " 57,\n",
              " 5921,\n",
              " 18,\n",
              " 5654,\n",
              " 6,\n",
              " 1444,\n",
              " 378,\n",
              " 41,\n",
              " 571,\n",
              " 94,\n",
              " 7,\n",
              " 3784,\n",
              " 9,\n",
              " 2,\n",
              " 360,\n",
              " 364,\n",
              " 5,\n",
              " 2,\n",
              " 651,\n",
              " 8,\n",
              " 7,\n",
              " 441,\n",
              " 3058,\n",
              " 15,\n",
              " 12,\n",
              " 7,\n",
              " 2,\n",
              " 10750,\n",
              " 359,\n",
              " 6,\n",
              " 2,\n",
              " 15586,\n",
              " 6833,\n",
              " 2486,\n",
              " 1041,\n",
              " 48744,\n",
              " 8,\n",
              " 2759,\n",
              " 1428,\n",
              " 22,\n",
              " 21823,\n",
              " 523,\n",
              " 35,\n",
              " 4614,\n",
              " 2487,\n",
              " 5,\n",
              " 2,\n",
              " 1243,\n",
              " 116,\n",
              " 31,\n",
              " 2,\n",
              " 7275,\n",
              " 28,\n",
              " 2963,\n",
              " 11483,\n",
              " 3,\n",
              " 397,\n",
              " 48745,\n",
              " 37,\n",
              " 17479,\n",
              " 7,\n",
              " 24,\n",
              " 300,\n",
              " 22,\n",
              " 2,\n",
              " 4720,\n",
              " 2995,\n",
              " 523,\n",
              " 7,\n",
              " 344,\n",
              " 6,\n",
              " 109,\n",
              " 22748,\n",
              " 7694,\n",
              " 37553,\n",
              " 13598,\n",
              " 5118,\n",
              " 8081,\n",
              " 2557,\n",
              " 3,\n",
              " 52,\n",
              " 37,\n",
              " 41976,\n",
              " 328,\n",
              " 9164,\n",
              " 7059,\n",
              " 12513,\n",
              " 3,\n",
              " 8405,\n",
              " 29282,\n",
              " 25,\n",
              " 112,\n",
              " 224,\n",
              " 242,\n",
              " 10,\n",
              " 61,\n",
              " 133,\n",
              " 2,\n",
              " 280,\n",
              " 1321,\n",
              " 5,\n",
              " 2,\n",
              " 120,\n",
              " 7,\n",
              " 688,\n",
              " 6,\n",
              " 2,\n",
              " 195,\n",
              " 12,\n",
              " 8,\n",
              " 271,\n",
              " 116,\n",
              " 81,\n",
              " 272,\n",
              " 577,\n",
              " 23,\n",
              " 3001,\n",
              " 837,\n",
              " 185,\n",
              " 1302,\n",
              " 4262,\n",
              " 17,\n",
              " 2533,\n",
              " 1233,\n",
              " 837,\n",
              " 1425,\n",
              " 837,\n",
              " 879,\n",
              " 3058,\n",
              " 152,\n",
              " 23,\n",
              " 965,\n",
              " 186,\n",
              " 2,\n",
              " 88,\n",
              " 391,\n",
              " 10,\n",
              " 123,\n",
              " 212,\n",
              " 3149,\n",
              " 69,\n",
              " 15,\n",
              " 37,\n",
              " 1685,\n",
              " 8,\n",
              " 14,\n",
              " 2232,\n",
              " 10,\n",
              " 416,\n",
              " 23,\n",
              " 133,\n",
              " 10,\n",
              " 14,\n",
              " 1627,\n",
              " 17,\n",
              " 8,\n",
              " 19,\n",
              " 15,\n",
              " 10,\n",
              " 287,\n",
              " 52,\n",
              " 10,\n",
              " 1420,\n",
              " 4,\n",
              " 1311,\n",
              " 17,\n",
              " 3058,\n",
              " 3,\n",
              " 190,\n",
              " 10027,\n",
              " 6,\n",
              " 2,\n",
              " 300,\n",
              " 2076,\n",
              " 5,\n",
              " 2085,\n",
              " 571,\n",
              " 24,\n",
              " 42,\n",
              " 571,\n",
              " 19,\n",
              " 7470,\n",
              " 7091,\n",
              " 4780,\n",
              " 36,\n",
              " 233,\n",
              " 30,\n",
              " 2934,\n",
              " 44,\n",
              " 17,\n",
              " 4,\n",
              " 24924,\n",
              " 6521,\n",
              " 36,\n",
              " 233,\n",
              " 493,\n",
              " 22,\n",
              " 623,\n",
              " 3,\n",
              " 77,\n",
              " 242,\n",
              " 18,\n",
              " 8,\n",
              " 70,\n",
              " 7518,\n",
              " 647,\n",
              " 691,\n",
              " 6521,\n",
              " 110,\n",
              " 653,\n",
              " 84,\n",
              " 1243,\n",
              " 19016,\n",
              " 688,\n",
              " 6,\n",
              " 67,\n",
              " 574,\n",
              " 5,\n",
              " 912,\n",
              " 2063,\n",
              " 41,\n",
              " 1243,\n",
              " 557,\n",
              " 149,\n",
              " 3058,\n",
              " 21,\n",
              " 199,\n",
              " 436,\n",
              " 3606,\n",
              " 18,\n",
              " 48,\n",
              " 7,\n",
              " 3344,\n",
              " 816,\n",
              " 1568,\n",
              " 46,\n",
              " 21,\n",
              " 51,\n",
              " 77,\n",
              " 9,\n",
              " 1209,\n",
              " 18,\n",
              " 127,\n",
              " 4252,\n",
              " 488]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##\n",
        "# apply text_pipeline to example_text\n",
        "text_pipeline(example_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lzZomgL3XOqx"
      },
      "outputs": [],
      "source": [
        "train_data_vect = []\n",
        "\n",
        "for i in range(0,len(train_data['review'])):\n",
        "  out = text_pipeline(train_data.review.iloc[i])\n",
        "  train_data_vect.append(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3PDr6m5ZH5o",
        "outputId": "87def419-0b7e-4c5a-cabc-5f46b217094d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[12,\n",
              " 13,\n",
              " 48,\n",
              " 10,\n",
              " 797,\n",
              " 2163,\n",
              " 534,\n",
              " 306,\n",
              " 2,\n",
              " 109,\n",
              " 1900,\n",
              " 2037,\n",
              " 4353,\n",
              " 6530,\n",
              " 3,\n",
              " 792,\n",
              " 4862,\n",
              " 12,\n",
              " 22053,\n",
              " 2,\n",
              " 12616,\n",
              " 229,\n",
              " 2,\n",
              " 6202,\n",
              " 82,\n",
              " 775,\n",
              " 56,\n",
              " 54,\n",
              " 21,\n",
              " 102,\n",
              " 5,\n",
              " 2,\n",
              " 29,\n",
              " 2013,\n",
              " 103,\n",
              " 36,\n",
              " 28,\n",
              " 37,\n",
              " 121,\n",
              " 1121,\n",
              " 12,\n",
              " 8,\n",
              " 7,\n",
              " 2367,\n",
              " 1185,\n",
              " 6,\n",
              " 458,\n",
              " 48,\n",
              " 550,\n",
              " 6,\n",
              " 93,\n",
              " 33,\n",
              " 25,\n",
              " 42,\n",
              " 905,\n",
              " 405,\n",
              " 28486,\n",
              " 17,\n",
              " 2,\n",
              " 157,\n",
              " 6,\n",
              " 2981,\n",
              " 27,\n",
              " 36139,\n",
              " 4390,\n",
              " 22,\n",
              " 4,\n",
              " 2943,\n",
              " 12,\n",
              " 47,\n",
              " 76,\n",
              " 222,\n",
              " 74,\n",
              " 128,\n",
              " 9,\n",
              " 81,\n",
              " 3152,\n",
              " 197,\n",
              " 22,\n",
              " 238,\n",
              " 3,\n",
              " 2,\n",
              " 435,\n",
              " 10,\n",
              " 202,\n",
              " 4963,\n",
              " 10,\n",
              " 141,\n",
              " 24,\n",
              " 65,\n",
              " 29,\n",
              " 17,\n",
              " 14598,\n",
              " 75,\n",
              " 366,\n",
              " 306,\n",
              " 4,\n",
              " 20,\n",
              " 19,\n",
              " 8,\n",
              " 202,\n",
              " 30,\n",
              " 309,\n",
              " 12,\n",
              " 57852,\n",
              " 40320,\n",
              " 15,\n",
              " 2,\n",
              " 1858,\n",
              " 13,\n",
              " 10158,\n",
              " 117,\n",
              " 421,\n",
              " 3,\n",
              " 46536,\n",
              " 46537,\n",
              " 15,\n",
              " 2,\n",
              " 1685,\n",
              " 11318,\n",
              " 572,\n",
              " 72,\n",
              " 427,\n",
              " 381,\n",
              " 10,\n",
              " 87,\n",
              " 23,\n",
              " 119,\n",
              " 48,\n",
              " 115,\n",
              " 369,\n",
              " 33,\n",
              " 11930,\n",
              " 38,\n",
              " 19,\n",
              " 46,\n",
              " 10,\n",
              " 14,\n",
              " 93,\n",
              " 10,\n",
              " 227,\n",
              " 6868,\n",
              " 17,\n",
              " 4,\n",
              " 365,\n",
              " 12367,\n",
              " 1165,\n",
              " 24136,\n",
              " 64,\n",
              " 57853,\n",
              " 57854,\n",
              " 9,\n",
              " 2,\n",
              " 469,\n",
              " 217,\n",
              " 1007,\n",
              " 6,\n",
              " 4194,\n",
              " 9,\n",
              " 4,\n",
              " 178,\n",
              " 5,\n",
              " 37,\n",
              " 441,\n",
              " 689,\n",
              " 617,\n",
              " 12,\n",
              " 71,\n",
              " 233,\n",
              " 239,\n",
              " 112,\n",
              " 842,\n",
              " 38,\n",
              " 173,\n",
              " 32,\n",
              " 221,\n",
              " 12,\n",
              " 13,\n",
              " 2,\n",
              " 431,\n",
              " 368,\n",
              " 58,\n",
              " 3773,\n",
              " 4,\n",
              " 279,\n",
              " 10307,\n",
              " 161,\n",
              " 1706,\n",
              " 191,\n",
              " 7,\n",
              " 2,\n",
              " 11711,\n",
              " 11516,\n",
              " 723,\n",
              " 1945,\n",
              " 2,\n",
              " 1198,\n",
              " 5,\n",
              " 2884,\n",
              " 11517,\n",
              " 3732,\n",
              " 1686,\n",
              " 3,\n",
              " 33011,\n",
              " 148,\n",
              " 10,\n",
              " 141,\n",
              " 4,\n",
              " 230,\n",
              " 5,\n",
              " 4,\n",
              " 207,\n",
              " 327,\n",
              " 3,\n",
              " 10,\n",
              " 141,\n",
              " 1069,\n",
              " 18,\n",
              " 90,\n",
              " 5,\n",
              " 134,\n",
              " 2838,\n",
              " 8766,\n",
              " 19,\n",
              " 10,\n",
              " 155,\n",
              " 23,\n",
              " 9264,\n",
              " 100,\n",
              " 5,\n",
              " 2,\n",
              " 4041,\n",
              " 306,\n",
              " 11,\n",
              " 16,\n",
              " 990,\n",
              " 38,\n",
              " 2,\n",
              " 16888,\n",
              " 495,\n",
              " 486,\n",
              " 2613,\n",
              " 248,\n",
              " 71,\n",
              " 77,\n",
              " 109,\n",
              " 109,\n",
              " 686,\n",
              " 10018,\n",
              " 62,\n",
              " 12853,\n",
              " 85,\n",
              " 71,\n",
              " 153,\n",
              " 1354,\n",
              " 6,\n",
              " 228,\n",
              " 134,\n",
              " 25,\n",
              " 4391,\n",
              " 34,\n",
              " 140,\n",
              " 17838,\n",
              " 209,\n",
              " 1143,\n",
              " 15,\n",
              " 4414,\n",
              " 5296,\n",
              " 34,\n",
              " 4,\n",
              " 25357,\n",
              " 2318,\n",
              " 3,\n",
              " 46538,\n",
              " 9,\n",
              " 30487,\n",
              " 11,\n",
              " 7,\n",
              " 4,\n",
              " 446,\n",
              " 15,\n",
              " 620,\n",
              " 5,\n",
              " 2,\n",
              " 714,\n",
              " 2961,\n",
              " 2,\n",
              " 1271,\n",
              " 16464,\n",
              " 3,\n",
              " 71,\n",
              " 3629,\n",
              " 2,\n",
              " 157,\n",
              " 1504,\n",
              " 2,\n",
              " 1240,\n",
              " 6,\n",
              " 1615,\n",
              " 2,\n",
              " 874,\n",
              " 1248,\n",
              " 6,\n",
              " 2,\n",
              " 302,\n",
              " 144,\n",
              " 2899,\n",
              " 3,\n",
              " 413,\n",
              " 624,\n",
              " 2,\n",
              " 269,\n",
              " 7,\n",
              " 3572,\n",
              " 992,\n",
              " 6,\n",
              " 30,\n",
              " 42,\n",
              " 13656,\n",
              " 15,\n",
              " 1260,\n",
              " 219,\n",
              " 67,\n",
              " 17839,\n",
              " 3,\n",
              " 40,\n",
              " 7,\n",
              " 32,\n",
              " 221,\n",
              " 29,\n",
              " 193,\n",
              " 1456,\n",
              " 9,\n",
              " 1085,\n",
              " 19,\n",
              " 10,\n",
              " 4940,\n",
              " 21195,\n",
              " 28487,\n",
              " 86,\n",
              " 2,\n",
              " 225,\n",
              " 68,\n",
              " 359,\n",
              " 69,\n",
              " 57,\n",
              " 29,\n",
              " 6,\n",
              " 3605,\n",
              " 17,\n",
              " 8,\n",
              " 13,\n",
              " 24,\n",
              " 196,\n",
              " 6,\n",
              " 8291,\n",
              " 4,\n",
              " 871,\n",
              " 3488,\n",
              " 1753,\n",
              " 21,\n",
              " 28,\n",
              " 6,\n",
              " 162,\n",
              " 198,\n",
              " 179,\n",
              " 4,\n",
              " 111,\n",
              " 12,\n",
              " 1635,\n",
              " 23,\n",
              " 470,\n",
              " 76,\n",
              " 222,\n",
              " 6,\n",
              " 328,\n",
              " 3,\n",
              " 3489,\n",
              " 36,\n",
              " 25,\n",
              " 52,\n",
              " 73,\n",
              " 1882,\n",
              " 4746,\n",
              " 15,\n",
              " 8,\n",
              " 1391,\n",
              " 11,\n",
              " 20,\n",
              " 7,\n",
              " 4,\n",
              " 3532,\n",
              " 2029,\n",
              " 18,\n",
              " 64,\n",
              " 2,\n",
              " 2424,\n",
              " 469,\n",
              " 527,\n",
              " 3,\n",
              " 4,\n",
              " 174,\n",
              " 2570,\n",
              " 17840,\n",
              " 2746,\n",
              " 1781,\n",
              " 6,\n",
              " 583,\n",
              " 8,\n",
              " 38,\n",
              " 2,\n",
              " 3813,\n",
              " 451,\n",
              " 160,\n",
              " 202,\n",
              " 353,\n",
              " 3876]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_vect[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DntxgvpROMqK",
        "outputId": "6510a05d-3afa-4bbd-bc3b-5b6ba38c9d0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((40000, 2), (5000, 2), (5000, 2))"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape, validation_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45jQylYJOdJI",
        "outputId": "c38932c9-232d-4927-ac40-28371304b02b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['review', 'sentiment'], dtype='object')"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ROeaWhUdHK5",
        "outputId": "cde108d1-4b93-4d09-b398-05f0a62f9ec6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5000, 2), (5000, 2))"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " validation_data.shape, test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "6774GTkpYcee"
      },
      "outputs": [],
      "source": [
        "train_data = [(label, data) for label, data in zip(train_data['sentiment'], train_data['review'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "46ZDkmYmc_bY"
      },
      "outputs": [],
      "source": [
        "validation_data = [(label, data) for label, data in zip(validation_data['sentiment'], validation_data['review'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hNSC7bkWc_jf"
      },
      "outputs": [],
      "source": [
        "test_data = [(label, data) for label, data in zip(test_data['sentiment'], test_data['review'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfqmCnXjcfJR",
        "outputId": "f2204f30-e671-49d1-ce57-de92993e2ac2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('negative',\n",
              " 'That\\'s what I kept asking myself during the many fights, screaming matches, swearing and general mayhem that permeate the 84 minutes. The comparisons also stand up when you think of the one-dimensional characters, who have so little depth that it is virtually impossible to care what happens to them. They are just badly written cyphers for the director to hang his multicultural beliefs on, a topic that has been done much better in other dramas both on TV and the cinema.<br /><br />I must confess, I\\'m not really one for spotting bad performances during a film, but it must be said that Nichola Burley (as the heroine\\'s slutty best friend) and Wasim Zakir (as the nasty, bullying brother) were absolutely terrible. I don\\'t know what acting school they graduated from, but if I was them I\\'d apply for a full refund post haste. Only Samina Awan in the lead role manages to impress in a cast of so-called British talent that we\\'ll probably never hear from again. At least, that\\'s the hope. Next time, hire a different scout.<br /><br />Another intriguing thought is the hideously fashionable soundtrack featuring the likes of Snow Patrol, Ian Brown and Keane. Now, I\\'m a bit of a music fan and I\\'m familiar with most of these artists output, but I didn\\'t recognise any of the tracks during this movie (apart from the omnipresent \"Run\"). B-sides, anyone? We get many, many musical montages which telegraph how we\\'re suppose to feel. These are accompanied by such startlingly original images as couples kissing by a swollen lake and canoodling in doorways. This is a problem, as none of the songs convey the mood efficiently, and we realise the director lacks the ability to carry the emotional journey to the audience through storytelling and dialogue alone.<br /><br />The ending is presumably meant to be just desserts, as everybody gets their comeuppance and there is at least one big shock in store.. But I remained resolutely unmoved because the script had given me no-one to root for. It\\'s not enough to tackle a hot-button issue, you have to actually give us a plot that hasn\\'t already been done to death and individuals who are more than window dressing. As it stands, this film is a noble failure, with only the promising lead actress and a few mildly diverting punch-ups to save it from the bin. 4/10. Must try harder..')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Zg2u1udboz",
        "outputId": "570eb964-d455-4553-817f-ca353043ed13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('negative',\n",
              " 'Hollywood has churned out yet another garbage that\\'s wildly overhyped and underwhelming on a first-time viewing basis. Hannibal is bad, terrible, inept, lame, droll, idiotic, contrived, laughable and utterly atrocious (no pun intended). Minor spoilers follow...<br /><br />This movie has huge logic holes - more than any Bruckheimer/Bay movie - or for that matter - any movie that exemplify the indulgence of Hollywood exaggeration. It\\'s a slick Hollywood production designed to cash in on Hannibal Lector mania, directed by \"so-somber-he-takes-this-way-too-seriously\" hack director Ridley Scott and produced by a hack Italian producer with an inflated ego whose credo is \"doesn\\'t matter whether film is s**t, money is good\".<br /><br />I can\\'t get over the fact that acclaimed screenwriters David Mamet and Steven Zaillian wrote this tripe adapted from a lame and pretentious book by a good-novelist-turned-hack-author Thomas Harris. David and Steven - well-known and immensely talented screenwriters - wasted their effort on a poor screenplay in exchange for fat paychecks. Another factor in the disappointment of this film.<br /><br />There are too many ludicrous scenes to list that are laughable in clunky execution and poor logic e.g. Starling/Pazzi cell-phone in the midst of Lecter pursuit that turns up Inspector Pazzi as the victim. Not to mention laughably bad dialogues delivered by Tony Hopkins with a smirk and Julianne Moore, Ray Liotta and others who cannot act with the straight face. Hopkins gives the true meaning of \"scenery-chewing\" along with hammy acting by Gary Oldman as a deformed psychopath bent on exacting revenge against Lecter.<br /><br />The gore effect is good, but only serves to repulse rather than provide suspense which is notably absent from Hannibal. The predecessor - Silence of the Lambs - is more believable with tension and suspense. Suspense is what made Silence of the Lamb work as a spectacular mix of psychological horror and thriller, not to mention superbly written and tensely directed. The \"brain dinner\" sequence is so laughably fake it borders on self-parody.<br /><br />The ending is kinda blatant and idiotic - are we supposed to believe that Lecter is still a menace to society with the last shot establishing his glittering eye glaring at you? Ooh, scary... <br /><br />')"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "validation_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSC7TS97dbvi",
        "outputId": "c4f3980f-2e34-4538-c91d-c0aaca970be4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('negative',\n",
              " 'the tortuous emotional impact is degrading, whether adult or adolescent the personal values shown in this movie belong in a bad psychodrama if anywhere at all. This movie has a plot, but it is all evil from start to end. This is no way for people to act and degrades both sexes all the way through the movie. teen killing - bad preteen sex - bad emotional battering - bad animal cruelty - bad psychological torture - bad parental neglect - bad the only merit if any is the excellent color shots of contrasting red, blond and green leaves a bad feeling for anyone that respects life and peace, what a bad mistake to make, or to watch... it is UGLY')"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJRy6SDMyMRd",
        "outputId": "f4799bad-abda-4b4d-ae6b-464d7c60c99b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "##\n",
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "l5xNlXhVyXSP"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# a function to apply pre-processing steps at a batch level\n",
        "import torch.nn as nn\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "\n",
        "    # iterate over all reviews in a batch\n",
        "    for _label, _text in batch:\n",
        "        # label preprocessing\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        # text preprocessing\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "\n",
        "        # store the processed text in a list\n",
        "        text_list.append(processed_text)\n",
        "\n",
        "        # store the length of processed text\n",
        "        # this will come handy in future when we want to know the original size of a text (without padding)\n",
        "        lengths.append(processed_text.size(0))\n",
        "\n",
        "    label_list = torch.tensor(label_list)\n",
        "    lengths = torch.tensor(lengths)\n",
        "\n",
        "    # pad the processed reviews to make their lengths consistant\n",
        "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
        "        text_list, batch_first=True)\n",
        "\n",
        "    # return\n",
        "    # 1. a list of processed and padded review texts\n",
        "    # 2. a list of processed labels\n",
        "    # 3. a list of review text original lengths (before padding)\n",
        "    return padded_text_list.to(device), label_list.to(device), lengths.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGqgPoGZyaIP",
        "outputId": "67bcf39c-95c4-4292-f049-07d144b7b1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text_batch.shape:  torch.Size([4, 417])\n",
            "label_batch:  tensor([0., 0., 1., 0.], device='cuda:0')\n",
            "length_batch:  tensor([417, 279,  93, 183], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    train_data, batch_size=4, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
        "\n",
        "print(\"text_batch.shape: \", text_batch.shape)\n",
        "print(\"label_batch: \", label_batch)\n",
        "print(\"length_batch: \", length_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wIt-ksHyl2K",
        "outputId": "51331b85-a469-4c20-e6f6-1bc327454fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([    4,  1332,   113,    63,  2839,     5,     9,     2,  1271,    17,\n",
            "          113,  4588,  2596,    22,  1702,  3956,     3,    85,    11,     7,\n",
            "          334,    34,  4236,    79,     6,  5747,  1344,     6,   255,    81,\n",
            "            2,    63,  2759,    22,     4, 17354,    36,   491,    37,    74,\n",
            "            6,    30,     4,  2219,  1621,    15,    70,    15,     4,    50,\n",
            "          603,     3,   330,     4,  6820,  1345,     7,    53,  3544,     6,\n",
            "           89,    15,     2,    63,  4237,    71,    66,     2,  1333,  1777,\n",
            "            2,  2303,     9,    27,   819,   293,  1511,     3,    85,    26,\n",
            "        33012,    18,     2,  1515, 12368,    12,   397,    89,     4,   317,\n",
            "            3,   704,    63,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(text_batch[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "a0b30BDsOoV9"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "valid_dl = DataLoader(\n",
        "    validation_data, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "test_dl = DataLoader(\n",
        "    test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "4tGxjhZWds-7"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# model training pipeline\n",
        "# https://github.com/rasbt/machine-learning-book/blob/main/ch15/ch15_part2.ipynb\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_loss = 0, 0\n",
        "    for text_batch, label_batch, lengths in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(text_batch, lengths)[:, 0]\n",
        "        loss = loss_fn(pred, label_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
        "        total_loss += loss.item() * label_batch.size(0)\n",
        "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "# model evaluation pipeline\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_loss = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for text_batch, label_batch, lengths in dataloader:\n",
        "            pred = model(text_batch, lengths)[:, 0]\n",
        "            loss = loss_fn(pred, label_batch)\n",
        "            total_acc += ((pred >= 0.5).float() == label_batch).float().sum().item()\n",
        "            total_loss += loss.item() * label_batch.size(0)\n",
        "    return total_acc / len(dataloader.dataset), total_loss / len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "f0h5KDZ7dtB7"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# https://github.com/rasbt/machine-learning-book/blob/main/ch15/ch15_part2.ipynb\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
        "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, lengths):\n",
        "        out = self.embedding(text)\n",
        "        out = nn.utils.rnn.pack_padded_sequence(\n",
        "            out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True\n",
        "        )\n",
        "        out, (hidden, cell) = self.rnn(out)\n",
        "        out = hidden[-1, :, :]\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TZhfh_CzdtE_"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vb)\n",
        "embed_dim = 20\n",
        "rnn_hidden_size = 64\n",
        "fc_hidden_size = 64\n",
        "\n",
        "torch.manual_seed(1)\n",
        "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "F8enQNRedtIH"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "waMpvUbqPbw9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-pJZ7hbd-A0",
        "outputId": "98194b90-cffe-4458-e99a-10e5306c7190"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "processing:  10%|â–ˆ         | 1/10 [00:56<08:26, 56.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 train accuracy: 0.8163; val accuracy: 0.7080\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rprocessing:  20%|â–ˆâ–ˆ        | 2/10 [01:53<07:33, 56.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 train accuracy: 0.8496; val accuracy: 0.8672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rprocessing:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [02:49<06:36, 56.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 train accuracy: 0.9030; val accuracy: 0.8756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rprocessing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [03:46<05:38, 56.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 train accuracy: 0.9282; val accuracy: 0.8930\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rprocessing:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [04:41<04:40, 56.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 train accuracy: 0.9438; val accuracy: 0.8956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rprocessing:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [05:36<03:43, 55.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 train accuracy: 0.9571; val accuracy: 0.8974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rprocessing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [06:31<02:46, 55.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 train accuracy: 0.9680; val accuracy: 0.8838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rprocessing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [07:27<01:50, 55.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 train accuracy: 0.9778; val accuracy: 0.8942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rprocessing:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [08:22<00:55, 55.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 train accuracy: 0.9845; val accuracy: 0.8948\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "processing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [09:17<00:00, 55.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 train accuracy: 0.9889; val accuracy: 0.8906\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "for epoch in tqdm(range(num_epochs),desc='processing'):\n",
        "    acc_train, loss_train = train(train_dl)\n",
        "    acc_valid, loss_valid = evaluate(valid_dl)\n",
        "    print(\n",
        "        f\"Epoch {epoch} train accuracy: {acc_train:.4f}; val accuracy: {acc_valid:.4f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "vvIMNZwjeAqk"
      },
      "outputs": [],
      "source": [
        "def classify_review(text):\n",
        "    text_list, lengths = [], []\n",
        "\n",
        "    # process review text with text_pipeline\n",
        "    # note: \"text_pipeline\" has dependency on data vocabulary\n",
        "    processed_text = torch.tensor(text_pipeline(text), dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "\n",
        "    # get processed review tokens length\n",
        "    lengths.append(processed_text.size(0))\n",
        "    lengths = torch.tensor(lengths)\n",
        "\n",
        "    # change the dimensions from (torch.Size([8]), torch.Size([1, 8]))\n",
        "    # nn.utils.rnn.pad_sequence(text_list, batch_first=True) does this too\n",
        "    padded_text_list = torch.unsqueeze(processed_text, 0)\n",
        "\n",
        "    # move tensors to correct device\n",
        "    padded_text_list = padded_text_list.to(device)\n",
        "    lengths = lengths.to(device)\n",
        "\n",
        "    # get prediction\n",
        "    model.eval()\n",
        "    pred = model(padded_text_list, lengths)\n",
        "    print(\"model pred: \", pred)\n",
        "\n",
        "    # positive or negative review\n",
        "    review_class = 'negative' # else case\n",
        "    if (pred>=0.5) == 1:\n",
        "        review_class = \"positive\"\n",
        "\n",
        "    print(\"review type: \", review_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "5zuvASl1eV0N"
      },
      "outputs": [],
      "source": [
        "##\n",
        "# create two random texts with strong positive and negative sentiments\n",
        "pos_review = 'i love this movie. it was so good.'\n",
        "neg_review = 'slow and boring. waste of time.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJAf3gXMeV3M",
        "outputId": "a2435b5e-4496-4efa-e0dd-e50f96aba4ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model pred:  tensor([[0.9024]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
            "review type:  positive\n"
          ]
        }
      ],
      "source": [
        "classify_review(pos_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0vCusZ1e1Ph",
        "outputId": "9afa9dea-25ad-4e85-89cc-94f55e042a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model pred:  tensor([[0.0025]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
            "review type:  negative\n"
          ]
        }
      ],
      "source": [
        "classify_review(neg_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pb3WP6ne4lg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
